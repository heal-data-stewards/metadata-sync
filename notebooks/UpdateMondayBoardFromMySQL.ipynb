{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook will develp the SOP for updating the Monday.com studies board consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = Path(\"/Users/hinashah/Documents/HEAL/MondayFolderUpdate_202406_CTN/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_values(df:pd.DataFrame, col_name:str='appl_id'):\n",
    "    if col_name in df.columns:\n",
    "        return df[ ~pd.isna(df[col_name])][col_name].drop_duplicates()\n",
    "    return None\n",
    "\n",
    "def get_na_count(df:pd.DataFrame, col_name:str='appl_id'):\n",
    "    if col_name in df.columns:\n",
    "        return len(df[pd.isna(df[col_name])])\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1476\n",
      "Index(['appl_id', 'xstudy_id', 'study_most_recent_appl', 'study_hdp_id',\n",
      "       'study_hdp_id_appl'],\n",
      "      dtype='object')\n",
      "appl_id                   object\n",
      "xstudy_id                 object\n",
      "study_most_recent_appl    object\n",
      "study_hdp_id              object\n",
      "study_hdp_id_appl         object\n",
      "dtype: object\n",
      "Number of distinct values in --appl_id--: 1467\n",
      "---- NA count: 0\n",
      "Number of funky looking appl_ids: 0\n",
      "Number of distinct values in --xstudy_id--: 1198\n",
      "---- NA count: 0\n",
      "Number of distinct values in --study_most_recent_appl--: 1189\n",
      "---- NA count: 0\n",
      "Number of funky looking appl_ids: 0\n",
      "Number of distinct values in --study_hdp_id--: 1160\n",
      "---- NA count: 51\n",
      " Number of funky looking HDPIDs: 0\n",
      "Number of distinct values in --study_hdp_id_appl--: 1151\n",
      "---- NA count: 51\n",
      "Number of funky looking appl_ids: 0\n"
     ]
    }
   ],
   "source": [
    "gt_file = pd.read_csv(input_dir/\"study_lookup_table.csv\", dtype=str)\n",
    "gt_file.replace(\"0\", np.NaN, inplace=True)\n",
    "\n",
    "print(len(gt_file))\n",
    "print(gt_file.columns)\n",
    "print(gt_file.dtypes)\n",
    "### QC the file:\n",
    "for k in gt_file.columns:\n",
    "    print(f\"Number of distinct values in --{k}--: {len(get_unique_values(gt_file, k))}\")\n",
    "    print(f\"---- NA count: {get_na_count(gt_file, k)}\")\n",
    "    ## Look for patterns?\n",
    "    if 'appl' in k:\n",
    "        d = gt_file[[ (not pd.isna(l)) and (not l.isdigit()) for l in gt_file[k] ]]\n",
    "        print(f\"Number of funky looking appl_ids: {len(d)}\")\n",
    "    elif k == 'study_hdp_id':\n",
    "        d = gt_file[ [ (not pd.isna(l)) and (re.match(r'HDP[\\d]+', l) is None) for l in gt_file[k]]]\n",
    "        print(f\" Number of funky looking HDPIDs: {len(d)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/Users/hinashah/Documents/HEAL/MondayFolderUpdate_202406_CTN/HEAL_Studies_Studies_never_added_to_the_Platform_legacy_1719346227.xlsx'), PosixPath('/Users/hinashah/Documents/HEAL/MondayFolderUpdate_202406_CTN/HEAL_Studies_HEAL_Studies_in_the_Platform_1719346253.xlsx')]\n",
      "38\n",
      "1208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_9064/1014237317.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  monday_board = pd.concat([monday_board, tmp_df])\n"
     ]
    }
   ],
   "source": [
    "## Import Monday Board \n",
    "## TODO: change to read in all groups\n",
    "board_files_list = list(input_dir.glob(\"HEAL_Studies_*.xlsx\"))\n",
    "print(board_files_list)\n",
    "monday_board = pd.DataFrame()\n",
    "for file_path in board_files_list:\n",
    "    tmp_df = pd.read_excel(file_path, skiprows=4, dtype={\"Most Recent Appl_ID\":str, \"Name\":str}, skipfooter=1)\n",
    "    group_name = ' '.join(file_path.name.split('_')[2:-1])\n",
    "    if group_name == 'Studies never added to the Platform legacy':\n",
    "        study_type = 'APPLIDONLY'\n",
    "    elif group_name == 'HEAL Studies in the Platform':\n",
    "        study_type = \"HDP\"\n",
    "    elif group_name == \"CTN Protocols\":\n",
    "        study_type == \"CTN\"\n",
    "    else:\n",
    "        study_type = \"Unknown\"\n",
    "    tmp_df['study_type'] = [study_type]*len(tmp_df)\n",
    "    monday_board = pd.concat([monday_board, tmp_df])\n",
    "    print(len(monday_board))\n",
    "\n",
    "# monday_board = pd.read_excel(input_dir/\"HEAL_Studies_1719341536.xlsx\", skiprows=4, dtype={\"Most Recent Appl_ID\":str}, skipfooter=1)\n",
    "# print(monday_board[\"Name\"].describe())\n",
    "# print(monday_board.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number records from Monday already in lookup table: 1198\n",
      "Number records from Monday that are not in lookup table: 10\n",
      "Number records from l0ookup that are not in Monday: 0\n"
     ]
    }
   ],
   "source": [
    "### Steps for updating Monday board:\n",
    "\n",
    "## From Study lookup table, get unique set of most_recent_appl, study_hdp_id, and study_hdp_id_appl\n",
    "lookup_fields = gt_file[['study_hdp_id', 'study_most_recent_appl', 'study_hdp_id_appl']].copy(deep=True).drop_duplicates()\n",
    "## Create a column \"Name\" or \"Key\" that will either have study_hdp_id OR most_recent_appl when study_hdp_id is empty\n",
    "lookup_fields['key'] = [m if pd.isna(h) else h for (h, m) in lookup_fields[['study_hdp_id', 'study_most_recent_appl']].values ]\n",
    "\n",
    "### A few checks:\n",
    "## How many of the \"keys\" from Monday board are in lookup fields?\n",
    "print(f\"Number records from Monday already in lookup table: {len(monday_board[monday_board.Name.isin(lookup_fields.key)])}\")\n",
    "## How many of the keys from MOnday board are not there in looup fields\n",
    "mondayboard_missingin_looup = monday_board[~monday_board.Name.isin(lookup_fields.key)]\n",
    "print(f\"Number records from Monday that are not in lookup table: {len(mondayboard_missingin_looup)}\")\n",
    "## How many of the keys from lookup fields are not there in Monday??\n",
    "lookup_missingin_mondayboard = lookup_fields[~lookup_fields.key.isin(monday_board.Name)]\n",
    "print(f\"Number records from l0ookup that are not in Monday: {len(lookup_missingin_mondayboard)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Most Recent Appl_ID</th>\n",
       "      <th>HDP appl_ID</th>\n",
       "      <th>Project #</th>\n",
       "      <th>Archived</th>\n",
       "      <th>HEAL-Related</th>\n",
       "      <th>Research Focus</th>\n",
       "      <th>Research Program</th>\n",
       "      <th>Title</th>\n",
       "      <th>Contact PI</th>\n",
       "      <th>...</th>\n",
       "      <th>Repo per PI</th>\n",
       "      <th>Repo per Platform</th>\n",
       "      <th>Platform Reg Time</th>\n",
       "      <th>CEDAR Form %</th>\n",
       "      <th>Repo Mapping</th>\n",
       "      <th>repo_22_2</th>\n",
       "      <th>repo_22_3</th>\n",
       "      <th>Creation Log</th>\n",
       "      <th>link to \"Get the Data\" Engagement Board</th>\n",
       "      <th>study_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>HDP00475</td>\n",
       "      <td>9916202</td>\n",
       "      <td>9916202.0</td>\n",
       "      <td>3UG1DA015831-17S6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Strategies to Prevent and Treat Opioid Add...</td>\n",
       "      <td>Prevention of Progression to Moderate or Sever...</td>\n",
       "      <td>The National Drug Abuse Treatment Clinical Tri...</td>\n",
       "      <td>WEISS, ROGER D.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NIDA Data Share</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kathy Jooss Nov 29, 2021 7:59 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>HDP00501</td>\n",
       "      <td>9905155</td>\n",
       "      <td>9905155.0</td>\n",
       "      <td>3UG1DA015815-18S6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Strategies to Prevent and Treat Opioid Add...</td>\n",
       "      <td>Prevention of Progression to Moderate or Sever...</td>\n",
       "      <td>Western States Node of the National Drug Abuse...</td>\n",
       "      <td>SORENSEN, JAMES L</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NIDA Data Share</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kathy Jooss Nov 29, 2021 7:59 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>HDP00614</td>\n",
       "      <td>9914612</td>\n",
       "      <td>9914612.0</td>\n",
       "      <td>3UG1DA013035-17S9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Strategies to Prevent and Treat Opioid Add...</td>\n",
       "      <td>Prevention of Progression to Moderate or Sever...</td>\n",
       "      <td>NIDA Clinical Trials Network: Greater New York...</td>\n",
       "      <td>ROTROSEN, JOHN P</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-12-21</td>\n",
       "      <td>84.6</td>\n",
       "      <td>NIDA Data Share</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kathy Jooss Nov 29, 2021 7:59 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>HDP00617</td>\n",
       "      <td>9905154</td>\n",
       "      <td>9905154.0</td>\n",
       "      <td>3UG1DA015815-18S5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Strategies to Prevent and Treat Opioid Add...</td>\n",
       "      <td>Prevention of Progression to Moderate or Sever...</td>\n",
       "      <td>Western States Node of the National Drug Abuse...</td>\n",
       "      <td>SORENSEN, JAMES L</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NIDA Data Share</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kathy Jooss Nov 29, 2021 7:59 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>HDP00695</td>\n",
       "      <td>9951611</td>\n",
       "      <td>9951611.0</td>\n",
       "      <td>3UG1DA015815-17S6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Strategies to Prevent and Treat Opioid Add...</td>\n",
       "      <td>Prevention of Progression to Moderate or Sever...</td>\n",
       "      <td>Western States Node of the National Drug Abuse...</td>\n",
       "      <td>SORENSEN, JAMES L</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NIDA Data Share</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kathy Jooss Nov 29, 2021 7:59 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>HDP00724</td>\n",
       "      <td>9951612</td>\n",
       "      <td>9951612.0</td>\n",
       "      <td>3UG1DA015815-17S7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Strategies to Prevent and Treat Opioid Add...</td>\n",
       "      <td>Prevention of Progression to Moderate or Sever...</td>\n",
       "      <td>Western States Node of the National Drug Abuse...</td>\n",
       "      <td>SORENSEN, JAMES L</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NIDA Data Share</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kathy Jooss Nov 29, 2021 7:59 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>HDP00734</td>\n",
       "      <td>10140552</td>\n",
       "      <td>10140552.0</td>\n",
       "      <td>3UG1DA040316-06S3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Strategies to Prevent and Treat Opioid Add...</td>\n",
       "      <td>Optimizing Care for People with Opioid Use Dis...</td>\n",
       "      <td>Suicide Prediction and Prevention for People a...</td>\n",
       "      <td>BART, GAVIN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NIDA Data Share</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Figshare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kathy Jooss Nov 29, 2021 7:59 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>HDP00897</td>\n",
       "      <td>10573954</td>\n",
       "      <td>10573954.0</td>\n",
       "      <td>3UG1DA015831-21S3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cross-Cutting Research</td>\n",
       "      <td>Training the Next Generation of Researchers in...</td>\n",
       "      <td>National Institute on Drug Abuse Clinical Tria...</td>\n",
       "      <td>D'ONOFRIO, GAIL</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NIDA Data Share</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NIDA Data Share</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kathy Jooss May 4, 2023 11:25 AM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>HDP01275</td>\n",
       "      <td>10583135</td>\n",
       "      <td>10583135.0</td>\n",
       "      <td>3UG1DA015815-21S1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New Strategies to Prevent and Treat Opioid Add...</td>\n",
       "      <td>Prevention of Progression to Moderate or Sever...</td>\n",
       "      <td>Western States Node of the National Drug Abuse...</td>\n",
       "      <td>KORTHUIS, PHILIP TODD</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NIDA Data Share</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kathy Jooss Sep 5, 2023 5:51 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>HDP01251</td>\n",
       "      <td>9895173</td>\n",
       "      <td>9895173.0</td>\n",
       "      <td>3UG1DA013035-18S2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NIDA Clinical Trials Network: Greater New York...</td>\n",
       "      <td>ROTROSEN, JOHN P</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hina Shah Jun 19, 2024 1:22 PM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name Most Recent Appl_ID  HDP appl_ID          Project # Archived  \\\n",
       "411  HDP00475             9916202    9916202.0  3UG1DA015831-17S6      NaN   \n",
       "430  HDP00501             9905155    9905155.0  3UG1DA015815-18S6      NaN   \n",
       "497  HDP00614             9914612    9914612.0  3UG1DA013035-17S9      NaN   \n",
       "499  HDP00617             9905154    9905154.0  3UG1DA015815-18S5      NaN   \n",
       "553  HDP00695             9951611    9951611.0  3UG1DA015815-17S6      NaN   \n",
       "574  HDP00724             9951612    9951612.0  3UG1DA015815-17S7      NaN   \n",
       "580  HDP00734            10140552   10140552.0  3UG1DA040316-06S3      NaN   \n",
       "611  HDP00897            10573954   10573954.0  3UG1DA015831-21S3      NaN   \n",
       "797  HDP01275            10583135   10583135.0  3UG1DA015815-21S1      NaN   \n",
       "852  HDP01251             9895173    9895173.0  3UG1DA013035-18S2      NaN   \n",
       "\n",
       "    HEAL-Related                                     Research Focus  \\\n",
       "411          NaN  New Strategies to Prevent and Treat Opioid Add...   \n",
       "430          NaN  New Strategies to Prevent and Treat Opioid Add...   \n",
       "497          NaN  New Strategies to Prevent and Treat Opioid Add...   \n",
       "499          NaN  New Strategies to Prevent and Treat Opioid Add...   \n",
       "553          NaN  New Strategies to Prevent and Treat Opioid Add...   \n",
       "574          NaN  New Strategies to Prevent and Treat Opioid Add...   \n",
       "580          NaN  New Strategies to Prevent and Treat Opioid Add...   \n",
       "611          NaN                             Cross-Cutting Research   \n",
       "797          NaN  New Strategies to Prevent and Treat Opioid Add...   \n",
       "852            Y                                                NaN   \n",
       "\n",
       "                                      Research Program  \\\n",
       "411  Prevention of Progression to Moderate or Sever...   \n",
       "430  Prevention of Progression to Moderate or Sever...   \n",
       "497  Prevention of Progression to Moderate or Sever...   \n",
       "499  Prevention of Progression to Moderate or Sever...   \n",
       "553  Prevention of Progression to Moderate or Sever...   \n",
       "574  Prevention of Progression to Moderate or Sever...   \n",
       "580  Optimizing Care for People with Opioid Use Dis...   \n",
       "611  Training the Next Generation of Researchers in...   \n",
       "797  Prevention of Progression to Moderate or Sever...   \n",
       "852                                                NaN   \n",
       "\n",
       "                                                 Title             Contact PI  \\\n",
       "411  The National Drug Abuse Treatment Clinical Tri...        WEISS, ROGER D.   \n",
       "430  Western States Node of the National Drug Abuse...      SORENSEN, JAMES L   \n",
       "497  NIDA Clinical Trials Network: Greater New York...       ROTROSEN, JOHN P   \n",
       "499  Western States Node of the National Drug Abuse...      SORENSEN, JAMES L   \n",
       "553  Western States Node of the National Drug Abuse...      SORENSEN, JAMES L   \n",
       "574  Western States Node of the National Drug Abuse...      SORENSEN, JAMES L   \n",
       "580  Suicide Prediction and Prevention for People a...            BART, GAVIN   \n",
       "611  National Institute on Drug Abuse Clinical Tria...        D'ONOFRIO, GAIL   \n",
       "797  Western States Node of the National Drug Abuse...  KORTHUIS, PHILIP TODD   \n",
       "852  NIDA Clinical Trials Network: Greater New York...       ROTROSEN, JOHN P   \n",
       "\n",
       "     ... Repo per PI Repo per Platform Platform Reg Time CEDAR Form %  \\\n",
       "411  ...         NaN               NaN               NaT          0.0   \n",
       "430  ...         NaN               NaN               NaT          0.0   \n",
       "497  ...         NaN               NaN        2022-12-21         84.6   \n",
       "499  ...         NaN               NaN               NaT          0.0   \n",
       "553  ...         NaN               NaN               NaT          0.0   \n",
       "574  ...         NaN               NaN               NaT          0.0   \n",
       "580  ...         NaN   NIDA Data Share               NaT          0.0   \n",
       "611  ...         NaN   NIDA Data Share               NaT          0.0   \n",
       "797  ...         NaN               NaN               NaT          0.0   \n",
       "852  ...         NaN               NaN               NaT          0.0   \n",
       "\n",
       "        Repo Mapping repo_22_2 repo_22_3                      Creation Log  \\\n",
       "411  NIDA Data Share       NaN       NaN  Kathy Jooss Nov 29, 2021 7:59 AM   \n",
       "430  NIDA Data Share       NaN       NaN  Kathy Jooss Nov 29, 2021 7:59 AM   \n",
       "497  NIDA Data Share       NaN       NaN  Kathy Jooss Nov 29, 2021 7:59 AM   \n",
       "499  NIDA Data Share       NaN       NaN  Kathy Jooss Nov 29, 2021 7:59 AM   \n",
       "553  NIDA Data Share       NaN       NaN  Kathy Jooss Nov 29, 2021 7:59 AM   \n",
       "574  NIDA Data Share       NaN       NaN  Kathy Jooss Nov 29, 2021 7:59 AM   \n",
       "580         Figshare       NaN       NaN  Kathy Jooss Nov 29, 2021 7:59 AM   \n",
       "611  NIDA Data Share       NaN       NaN  Kathy Jooss May 4, 2023 11:25 AM   \n",
       "797  NIDA Data Share       NaN       NaN   Kathy Jooss Sep 5, 2023 5:51 PM   \n",
       "852              NaN       NaN       NaN    Hina Shah Jun 19, 2024 1:22 PM   \n",
       "\n",
       "     link to \"Get the Data\" Engagement Board  study_type  \n",
       "411                                      NaN         HDP  \n",
       "430                                      NaN         HDP  \n",
       "497                                      NaN         HDP  \n",
       "499                                      NaN         HDP  \n",
       "553                                      NaN         HDP  \n",
       "574                                      NaN         HDP  \n",
       "580                                      NaN         HDP  \n",
       "611                                      NaN         HDP  \n",
       "797                                      NaN         HDP  \n",
       "852                                      NaN         HDP  \n",
       "\n",
       "[10 rows x 39 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mondayboard_missingin_looup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Awards table has: 1618 entries, with 1618 appl_ids\n",
      "Reporter table has: 1617 entries, with 1617 appl_ids\n",
      "Platform generated table has: 1319 entries, with 1290 appl_ids\n",
      "Platform table has 1290 unique HDP IDs\n",
      "Repo mapping table has: 1323 entrie, with 1323 appl_ids\n",
      "Repo mapping table has: 1059 entrie, with 1059 appl_ids\n",
      "Research Network table has: 1669 entrie, with 1669 appl_ids\n"
     ]
    }
   ],
   "source": [
    "# Get rest of the tables\n",
    "convert_dict = {'appl_id':str}\n",
    "\n",
    "awards_df = pd.read_csv(input_dir/\"awards.csv\", low_memory=False, dtype=convert_dict)\n",
    "awards_df = awards_df.dropna(how='all')\n",
    "print(f\"Awards table has: {len(awards_df)} entries, with {len(get_unique_values(awards_df))} appl_ids\")\n",
    "reporter_df = pd.read_csv(input_dir/\"reporter.csv\", low_memory=False, dtype=convert_dict)\n",
    "reporter_df = reporter_df.dropna(how='all')\n",
    "print(f\"Reporter table has: {len(reporter_df)} entries, with {len(get_unique_values(reporter_df))} appl_ids\")\n",
    "progress_tracker_df = pd.read_csv(input_dir/\"progress_tracker.csv\", low_memory=False, dtype=convert_dict)\n",
    "print(f\"Platform generated table has: {len(progress_tracker_df)} entries, with {len(get_unique_values(progress_tracker_df))} appl_ids\")\n",
    "print(f\"Platform table has {len(get_unique_values(progress_tracker_df))} unique HDP IDs\")\n",
    "repo_maping_df = pd.read_csv(input_dir/\"repo_mapping.csv\", low_memory=False, dtype=convert_dict)\n",
    "print(f\"Repo mapping table has: {len(repo_maping_df)} entrie, with {len(get_unique_values(repo_maping_df))} appl_ids\")\n",
    "pi_emails_df = pd.read_csv(input_dir/\"pi_emails.csv\", low_memory=False, dtype=convert_dict)\n",
    "print(f\"Repo mapping table has: {len(pi_emails_df)} entrie, with {len(get_unique_values(pi_emails_df))} appl_ids\")\n",
    "resnet_df = pd.read_csv(input_dir/\"research_networks.csv\", low_memory=False, dtype=convert_dict)\n",
    "print(f\"Research Network table has: {len(resnet_df)} entrie, with {len(get_unique_values(resnet_df))} appl_ids\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1467\n",
      "     study_most_recent_appl                   pi_email_latest\n",
      "1                   9755001                 kwatkins@rand.org\n",
      "2                   9850412                   damico@rand.org\n",
      "4                  10478911                 LYNN.DEBAR@KP.ORG\n",
      "8                  10468778          cheville.andrea@mayo.edu\n",
      "11                 10054792                   xcao11@jhmi.edu\n",
      "...                     ...                               ...\n",
      "1454               10167785               bahmedani@yahoo.com\n",
      "1455               10331849                  tbrocki1@JHU.EDU\n",
      "1457               10197811                  kzivin@UMICH.EDU\n",
      "1458               10197809            Gregory.E.Simon@kp.org\n",
      "1460                9823898  d-mencihella@md.northwestern.edu\n",
      "\n",
      "[875 rows x 2 columns]\n",
      "count    874.000000\n",
      "mean       1.001144\n",
      "std        0.033826\n",
      "min        1.000000\n",
      "25%        1.000000\n",
      "50%        1.000000\n",
      "75%        1.000000\n",
      "max        2.000000\n",
      "dtype: float64\n",
      "1467\n",
      "     study_most_recent_appl                  pi_email\n",
      "0                   9860408                          \n",
      "1                   9755001         kwatkins@rand.org\n",
      "2                   9850412           damico@rand.org\n",
      "4                  10478911         LYNN.DEBAR@KP.ORG\n",
      "8                  10468778  cheville.andrea@mayo.edu\n",
      "...                     ...                       ...\n",
      "1462               10022491                          \n",
      "1463               10493291                          \n",
      "1464                9555046                          \n",
      "1465                9775470                          \n",
      "1466               10589995                          \n",
      "\n",
      "[1189 rows x 2 columns]\n",
      "     study_most_recent_appl                  pi_email  \\\n",
      "0                   9860408                             \n",
      "1                   9755001         kwatkins@rand.org   \n",
      "2                   9850412           damico@rand.org   \n",
      "3                  10478911         LYNN.DEBAR@KP.ORG   \n",
      "4                  10468778  cheville.andrea@mayo.edu   \n",
      "...                     ...                       ...   \n",
      "1184               10022491                             \n",
      "1185               10493291                             \n",
      "1186                9555046                             \n",
      "1187                9775470                             \n",
      "1188               10589995                             \n",
      "\n",
      "                 Contact Email          pi_email_updated  \n",
      "0                                                         \n",
      "1            kwatkins@rand.org         kwatkins@rand.org  \n",
      "2              damico@rand.org           damico@rand.org  \n",
      "3            LYNN.DEBAR@KP.ORG         LYNN.DEBAR@KP.ORG  \n",
      "4     cheville.andrea@mayo.edu  cheville.andrea@mayo.edu  \n",
      "...                        ...                       ...  \n",
      "1184                                                      \n",
      "1185                                                      \n",
      "1186                                                      \n",
      "1187                                                      \n",
      "1188                                                      \n",
      "\n",
      "[1189 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_9064/1495752057.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  appl_ids_emails['pi_email'].fillna('', inplace=True)\n",
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_9064/1495752057.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  pi_emails_df_updated_monday['Contact Email'].replace('-', '', inplace=True)\n",
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_9064/1495752057.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  pi_emails_df_updated_monday['Contact Email'].fillna('', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## Manipulate emails to carry forward emails from a previous appl_id to the most recent one according to the lookup table and email table\n",
    "appl_ids = gt_file[['appl_id', 'study_most_recent_appl']].drop_duplicates()\n",
    "print(len(appl_ids))\n",
    "appl_ids_emails = pd.merge(appl_ids, pi_emails_df, how='left', on='appl_id')\n",
    "\n",
    "most_recent_emails = appl_ids_emails[ ~pd.isna(appl_ids_emails.pi_email)][['study_most_recent_appl', 'pi_email']].drop_duplicates()\n",
    "most_recent_emails.rename(columns={'pi_email':'pi_email_latest'}, inplace=True)\n",
    "print(most_recent_emails)\n",
    "email_counts = most_recent_emails.groupby('study_most_recent_appl').size()\n",
    "appl_ids_counts = appl_ids_emails.groupby('study_most_recent_appl').size()\n",
    "\n",
    "print(email_counts.describe())\n",
    "appl_ids_emails['email_count'] = [email_counts[k] if k in email_counts else 0 for k in appl_ids_emails['study_most_recent_appl']]\n",
    "appl_ids_emails['applid_count'] = [appl_ids_counts[k] if k in appl_ids_counts else 0 for k in appl_ids_emails['study_most_recent_appl']]\n",
    "appl_ids_emails['pi_email'].fillna('', inplace=True)\n",
    "appl_ids_emails['keep'] = [1 if (c==0 or (c==1 and len(e)>0) or (c>1 and a==m)) else 0 for (c,a,m,e) in appl_ids_emails[['email_count', 'appl_id', 'study_most_recent_appl', 'pi_email' ]].values]\n",
    "print(len(appl_ids_emails))\n",
    "\n",
    "pi_emails_df_updated = appl_ids_emails[appl_ids_emails['keep']==1][['study_most_recent_appl', 'pi_email']].drop_duplicates()\n",
    "pi_emails_df_updated['pi_email'] = [k.strip() for k in pi_emails_df_updated['pi_email']]\n",
    "print(pi_emails_df_updated)\n",
    "\n",
    "## Get Monday board emails, and fill in any that are different from mysql..\n",
    "pi_emails_df_updated_monday = pd.merge(pi_emails_df_updated, monday_board[['Most Recent Appl_ID', 'Contact Email']].drop_duplicates(), how='left', left_on='study_most_recent_appl', right_on='Most Recent Appl_ID').drop(columns='Most Recent Appl_ID')\n",
    "pi_emails_df_updated_monday['Contact Email'].replace('-', '', inplace=True)\n",
    "pi_emails_df_updated_monday['Contact Email'].fillna('', inplace=True)\n",
    "pi_emails_df_updated_monday['pi_email_updated'] = [me if (len(e)==0 and len(me) > 1) else e for (e,me) in pi_emails_df_updated_monday[['pi_email', 'Contact Email']].values]\n",
    "print(pi_emails_df_updated_monday)\n",
    "pi_emails_df_updated_monday.to_csv(input_dir/\"email_updates.csv\", index=False)\n",
    "appl_ids_emails.to_csv(input_dir/\"email_counts.csv\", index=False)\n",
    "\n",
    "pi_emails_df_updated = pi_emails_df_updated_monday[['study_most_recent_appl', 'pi_email_updated']].rename(columns={'pi_email_updated':'pi_email'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collect fields from report/awards tables that are required by Monday Board\n",
    "rename_dict = {'proj_num':'Project #', \n",
    "               'proj_title':'Title',\n",
    "                'rfa':'Research Focus',\n",
    "                'res_prg':'Research Program',\n",
    "                'ctc_pi_nm':'Contact PI',\n",
    "                'pi_email':'Contact Email',\n",
    "                'adm_ic':'Administering IC',\n",
    "                'prg_ofc':'NIH PO',\n",
    "                'org_nm': 'Institution(s)',\n",
    "                'pi':'PI(s)',\n",
    "                'org_cy':'City',\n",
    "                'org_st':'State',\n",
    "                'act_code':'Activity Code',\n",
    "                'awd_ty':'Award Type',\n",
    "                'fisc_yr':'Award Year',\n",
    "                'tot_fund':'Total Funded',\n",
    "                'proj_abs':'Summary',\n",
    "                'fund_mech': 'SBIR/STTR',\n",
    "                'dai_res':'DAI Import Status',\n",
    "                'proj_strt_date':'Project Start',\n",
    "                'proj_end_date':'Project End',\n",
    "                'proj_url':'Reporter Link',\n",
    "                'res_net':'Network',\n",
    "                'repo_22_1':'Repo Mapping',\n",
    "                'repo_22_2':'repo_22_2',\n",
    "                'repo_22_3':'repo_22_3',\n",
    "                'time_of_registration':'Platform Reg Time',\n",
    "                'overall_percent_complete':'CEDAR Form %',\n",
    "                'repository_name' : 'Repo per Platform',\n",
    "                'archived':'Archived',\n",
    "                'heal_funded':'HEAL-Related'\n",
    "                }\n",
    "\n",
    "def create_mysql_subset(in_df:pd.DataFrame, extra_fields = ['appl_id']):\n",
    "    subset = in_df[[k for k in rename_dict.keys() if k in in_df.columns] + extra_fields].copy(deep=True)\n",
    "    subset.rename(columns={k:v for k,v in rename_dict.items() if k in in_df.columns}, inplace=True)\n",
    "    return subset\n",
    "    \n",
    "mysql_fields_reporter = create_mysql_subset(awards_df)\n",
    "mysql_fields_awards = create_mysql_subset(reporter_df)\n",
    "myql_fields_repomapping = create_mysql_subset(repo_maping_df)\n",
    "mysql_fields_platform = create_mysql_subset(progress_tracker_df, extra_fields=['hdp_id'])\n",
    "mysql_fields_piemails = create_mysql_subset(pi_emails_df_updated, extra_fields=['study_most_recent_appl'])\n",
    "mysql_fields_resnet = create_mysql_subset(resnet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1198\n",
      "1198\n",
      "1198\n",
      "1198\n",
      "1198\n",
      "1198\n",
      "1198\n",
      "1198\n"
     ]
    }
   ],
   "source": [
    "print(len(lookup_fields))\n",
    "data_merge_1 = pd.merge(lookup_fields, mysql_fields_reporter, how='left', left_on='study_most_recent_appl', right_on='appl_id').drop(columns='appl_id')\n",
    "print(len(data_merge_1))\n",
    "data_merge_2 = pd.merge(data_merge_1, mysql_fields_awards, how='left', left_on='study_most_recent_appl', right_on='appl_id').drop(columns='appl_id')\n",
    "print(len(data_merge_2))\n",
    "data_merge_1 = pd.merge(data_merge_2, myql_fields_repomapping, how='left', left_on='study_most_recent_appl', right_on='appl_id').drop(columns='appl_id')\n",
    "print(len(data_merge_1))\n",
    "data_merge_2 = pd.merge(data_merge_1, mysql_fields_platform, how='left', left_on='study_hdp_id', right_on='hdp_id')\n",
    "print(len(data_merge_2))\n",
    "data_merge_1 = pd.merge(data_merge_2, mysql_fields_resnet, how='left', left_on='study_most_recent_appl', right_on='appl_id').drop(columns='appl_id')\n",
    "print(len(data_merge_1))\n",
    "combined_data_ph1 = pd.merge(data_merge_1, mysql_fields_piemails, how='left', on='study_most_recent_appl')\n",
    "print(len(combined_data_ph1))\n",
    "print(len(combined_data_ph1.drop_duplicates()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty values for each of the fields gathered:\n",
      "Project # : 0\n",
      "Title : 0\n",
      "Research Focus : 13\n",
      "Research Program : 77\n",
      "Contact PI : 0\n",
      "Contact Email : 0\n",
      "Administering IC : 0\n",
      "NIH PO : 58\n",
      "Institution(s) : 0\n",
      "PI(s) : 0\n",
      "City : 5\n",
      "State : 7\n",
      "Activity Code : 0\n",
      "Award Type : 0\n",
      "Award Year : 0\n",
      "Total Funded : 0\n",
      "Summary : 8\n",
      "SBIR/STTR : 0\n",
      "DAI Import Status : 708\n",
      "Project Start : 0\n",
      "Project End : 0\n",
      "Reporter Link : 0\n",
      "Network : 777\n",
      "Repo Mapping : 731\n",
      "repo_22_2 : 1090\n",
      "repo_22_3 : 1190\n",
      "Platform Reg Time : 864\n",
      "CEDAR Form % : 38\n",
      "Repo per Platform : 1056\n",
      "Archived : 38\n",
      "HEAL-Related : 21\n"
     ]
    }
   ],
   "source": [
    "## Find out which columns have NA values, and investigate for incompletemess?\n",
    "print(\"Number of empty values for each of the fields gathered:\")\n",
    "for k in rename_dict.values():\n",
    "    print(f\"{k} : {get_na_count(combined_data_ph1, k)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_9064/493364525.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  ctn_data['project_title'].replace('0', '', inplace=True)\n",
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_9064/493364525.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ctn_data['project_title'].replace('0', '', inplace=True)\n",
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_9064/493364525.py:40: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  ctn_fields_platform['PI(s)'].fillna('', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_hdp_id</th>\n",
       "      <th>study_most_recent_appl</th>\n",
       "      <th>study_hdp_id_appl</th>\n",
       "      <th>key</th>\n",
       "      <th>Research Focus</th>\n",
       "      <th>Research Program</th>\n",
       "      <th>DAI Import Status</th>\n",
       "      <th>HEAL-Related</th>\n",
       "      <th>Project #</th>\n",
       "      <th>Title</th>\n",
       "      <th>...</th>\n",
       "      <th>Repo Mapping</th>\n",
       "      <th>repo_22_2</th>\n",
       "      <th>repo_22_3</th>\n",
       "      <th>Platform Reg Time</th>\n",
       "      <th>CEDAR Form %</th>\n",
       "      <th>Repo per Platform</th>\n",
       "      <th>Archived</th>\n",
       "      <th>hdp_id</th>\n",
       "      <th>Network</th>\n",
       "      <th>Contact Email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HDP00632</td>\n",
       "      <td>9860408</td>\n",
       "      <td>9860408</td>\n",
       "      <td>HDP00632</td>\n",
       "      <td>New Strategies to Prevent and Treat Opioid Add...</td>\n",
       "      <td>Preventing Opioid Use Disorder</td>\n",
       "      <td>NO</td>\n",
       "      <td>Y</td>\n",
       "      <td>3U01AA021691-08S1</td>\n",
       "      <td>National Consortium on Alcohol and Neurodevelo...</td>\n",
       "      <td>...</td>\n",
       "      <td>NIMH Data Archive</td>\n",
       "      <td>Vivli</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>live</td>\n",
       "      <td>HDP00632</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HDP00696</td>\n",
       "      <td>9755001</td>\n",
       "      <td>9755001</td>\n",
       "      <td>HDP00696</td>\n",
       "      <td>New Strategies to Prevent and Treat Opioid Add...</td>\n",
       "      <td>Optimizing Care for People with Opioid Use Dis...</td>\n",
       "      <td>NO</td>\n",
       "      <td>Y</td>\n",
       "      <td>3R34AA025480-02S1</td>\n",
       "      <td>Implementing Medication-Assisted Therapy for S...</td>\n",
       "      <td>...</td>\n",
       "      <td>Vivli</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>live</td>\n",
       "      <td>HDP00696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kwatkins@rand.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HDP00509</td>\n",
       "      <td>9850412</td>\n",
       "      <td>9850412</td>\n",
       "      <td>HDP00509</td>\n",
       "      <td>New Strategies to Prevent and Treat Opioid Add...</td>\n",
       "      <td>Preventing Opioid Use Disorder</td>\n",
       "      <td>NO</td>\n",
       "      <td>Y</td>\n",
       "      <td>3R01AA025848-03S1</td>\n",
       "      <td>AOD Use Trajectories from Age 10 to 24: Multi-...</td>\n",
       "      <td>...</td>\n",
       "      <td>NIMH Data Archive</td>\n",
       "      <td>Vivli</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>live</td>\n",
       "      <td>HDP00509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>damico@rand.org</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HDP00242</td>\n",
       "      <td>10478911</td>\n",
       "      <td>9869480</td>\n",
       "      <td>HDP00242</td>\n",
       "      <td>Clinical Research in Pain Management</td>\n",
       "      <td>Pain Management Effectiveness Research Network</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>5UH3AG067493-04</td>\n",
       "      <td>Tailored Non-Pharmacotherapy Services for Chro...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-02-14T10:30:05-08:00</td>\n",
       "      <td>80.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>live</td>\n",
       "      <td>HDP00242</td>\n",
       "      <td>Pain ERN</td>\n",
       "      <td>LYNN.DEBAR@KP.ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HDP00391</td>\n",
       "      <td>10468778</td>\n",
       "      <td>9876435</td>\n",
       "      <td>HDP00391</td>\n",
       "      <td>Clinical Research in Pain Management</td>\n",
       "      <td>Pragmatic and Implementation Studies for the M...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>5UH3AG067593-04</td>\n",
       "      <td>Non-pharmacological Options in postoperative H...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024-02-08T05:59:13-08:00</td>\n",
       "      <td>23.1</td>\n",
       "      <td>ICPSR</td>\n",
       "      <td>live</td>\n",
       "      <td>HDP00391</td>\n",
       "      <td>PRISM</td>\n",
       "      <td>cheville.andrea@mayo.edu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>HDP01320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP01320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTN-0110</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>live</td>\n",
       "      <td>HDP01320</td>\n",
       "      <td>CTN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>HDP01321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP01321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTN-0096</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>live</td>\n",
       "      <td>HDP01321</td>\n",
       "      <td>CTN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>HDP01322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP01322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTN-0084-A-2</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>live</td>\n",
       "      <td>HDP01322</td>\n",
       "      <td>CTN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>HDP01323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP01323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTN-0094</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>live</td>\n",
       "      <td>HDP01323</td>\n",
       "      <td>CTN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>HDP01324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP01324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTN-0146</td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>live</td>\n",
       "      <td>HDP01324</td>\n",
       "      <td>CTN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1238 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     study_hdp_id study_most_recent_appl study_hdp_id_appl       key  \\\n",
       "0        HDP00632                9860408           9860408  HDP00632   \n",
       "1        HDP00696                9755001           9755001  HDP00696   \n",
       "2        HDP00509                9850412           9850412  HDP00509   \n",
       "3        HDP00242               10478911           9869480  HDP00242   \n",
       "4        HDP00391               10468778           9876435  HDP00391   \n",
       "...           ...                    ...               ...       ...   \n",
       "1314     HDP01320                    NaN               NaN  HDP01320   \n",
       "1315     HDP01321                    NaN               NaN  HDP01321   \n",
       "1316     HDP01322                    NaN               NaN  HDP01322   \n",
       "1317     HDP01323                    NaN               NaN  HDP01323   \n",
       "1318     HDP01324                    NaN               NaN  HDP01324   \n",
       "\n",
       "                                         Research Focus  \\\n",
       "0     New Strategies to Prevent and Treat Opioid Add...   \n",
       "1     New Strategies to Prevent and Treat Opioid Add...   \n",
       "2     New Strategies to Prevent and Treat Opioid Add...   \n",
       "3                  Clinical Research in Pain Management   \n",
       "4                  Clinical Research in Pain Management   \n",
       "...                                                 ...   \n",
       "1314                                                NaN   \n",
       "1315                                                NaN   \n",
       "1316                                                NaN   \n",
       "1317                                                NaN   \n",
       "1318                                                NaN   \n",
       "\n",
       "                                       Research Program DAI Import Status  \\\n",
       "0                        Preventing Opioid Use Disorder                NO   \n",
       "1     Optimizing Care for People with Opioid Use Dis...                NO   \n",
       "2                        Preventing Opioid Use Disorder                NO   \n",
       "3        Pain Management Effectiveness Research Network               NaN   \n",
       "4     Pragmatic and Implementation Studies for the M...               NaN   \n",
       "...                                                 ...               ...   \n",
       "1314                                                NaN               NaN   \n",
       "1315                                                NaN               NaN   \n",
       "1316                                                NaN               NaN   \n",
       "1317                                                NaN               NaN   \n",
       "1318                                                NaN               NaN   \n",
       "\n",
       "     HEAL-Related          Project #  \\\n",
       "0               Y  3U01AA021691-08S1   \n",
       "1               Y  3R34AA025480-02S1   \n",
       "2               Y  3R01AA025848-03S1   \n",
       "3               Y    5UH3AG067493-04   \n",
       "4               Y    5UH3AG067593-04   \n",
       "...           ...                ...   \n",
       "1314          NaN           CTN-0110   \n",
       "1315          NaN           CTN-0096   \n",
       "1316          NaN       CTN-0084-A-2   \n",
       "1317          NaN           CTN-0094   \n",
       "1318          NaN           CTN-0146   \n",
       "\n",
       "                                                  Title  ...  \\\n",
       "0     National Consortium on Alcohol and Neurodevelo...  ...   \n",
       "1     Implementing Medication-Assisted Therapy for S...  ...   \n",
       "2     AOD Use Trajectories from Age 10 to 24: Multi-...  ...   \n",
       "3     Tailored Non-Pharmacotherapy Services for Chro...  ...   \n",
       "4     Non-pharmacological Options in postoperative H...  ...   \n",
       "...                                                 ...  ...   \n",
       "1314                                                     ...   \n",
       "1315                                                     ...   \n",
       "1316                                                     ...   \n",
       "1317                                                     ...   \n",
       "1318                                                     ...   \n",
       "\n",
       "           Repo Mapping repo_22_2 repo_22_3          Platform Reg Time  \\\n",
       "0     NIMH Data Archive     Vivli       NaN                        NaN   \n",
       "1                 Vivli       NaN       NaN                        NaN   \n",
       "2     NIMH Data Archive     Vivli       NaN                        NaN   \n",
       "3                   NaN       NaN       NaN  2023-02-14T10:30:05-08:00   \n",
       "4                   NaN       NaN       NaN  2024-02-08T05:59:13-08:00   \n",
       "...                 ...       ...       ...                        ...   \n",
       "1314                NaN       NaN       NaN                        NaN   \n",
       "1315                NaN       NaN       NaN                        NaN   \n",
       "1316                NaN       NaN       NaN                        NaN   \n",
       "1317                NaN       NaN       NaN                        NaN   \n",
       "1318                NaN       NaN       NaN                        NaN   \n",
       "\n",
       "     CEDAR Form % Repo per Platform Archived    hdp_id   Network  \\\n",
       "0             0.0               NaN     live  HDP00632       NaN   \n",
       "1             0.0               NaN     live  HDP00696       NaN   \n",
       "2             0.0               NaN     live  HDP00509       NaN   \n",
       "3            80.8               NaN     live  HDP00242  Pain ERN   \n",
       "4            23.1             ICPSR     live  HDP00391     PRISM   \n",
       "...           ...               ...      ...       ...       ...   \n",
       "1314          0.0               NaN     live  HDP01320       CTN   \n",
       "1315          0.0               NaN     live  HDP01321       CTN   \n",
       "1316          0.0               NaN     live  HDP01322       CTN   \n",
       "1317          0.0               NaN     live  HDP01323       CTN   \n",
       "1318          0.0               NaN     live  HDP01324       CTN   \n",
       "\n",
       "                 Contact Email  \n",
       "0                               \n",
       "1            kwatkins@rand.org  \n",
       "2              damico@rand.org  \n",
       "3            LYNN.DEBAR@KP.ORG  \n",
       "4     cheville.andrea@mayo.edu  \n",
       "...                        ...  \n",
       "1314                       NaN  \n",
       "1315                       NaN  \n",
       "1316                       NaN  \n",
       "1317                       NaN  \n",
       "1318                       NaN  \n",
       "\n",
       "[1238 rows x 36 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Add CTN  data\n",
    "ctn_data = progress_tracker_df[[k.startswith('CTN') for k in progress_tracker_df['project_num']]]\n",
    "ctn_data['project_title'].replace('0', '', inplace=True)\n",
    "\n",
    "print(len(ctn_data))\n",
    "rename_dict = {'project_num':'Project #', \n",
    "               'project_title':'Title',\n",
    "                # 'rfa':'Research Focus',\n",
    "                # 'res_prg':'Research Program',\n",
    "                # 'investigators_name':'Contact PI',\n",
    "                # 'pi_email':'Contact Email',\n",
    "                # 'adm_ic':'Administering IC',\n",
    "                # 'prg_ofc':'NIH PO',\n",
    "                # 'org_nm': 'Institution(s)',\n",
    "                'investigators_name':'PI(s)',\n",
    "                # 'org_cy':'City',\n",
    "                # 'org_st':'State',\n",
    "                # 'act_code':'Activity Code',\n",
    "                'award_type':'Award Type',\n",
    "                'year_awarded':'Award Year',\n",
    "                'award_amount':'Total Funded',\n",
    "                'study_name':'Summary',\n",
    "                # 'fund_mech': 'SBIR/STTR',\n",
    "                # 'dai_res':'DAI Import Status',\n",
    "                # 'proj_strt_date':'Project Start',\n",
    "                'proj_end_date':'Project End',\n",
    "                'nih_reporter_link':'Reporter Link',\n",
    "                # 'res_net':'Network',\n",
    "                # 'repo_22_1':'Repo Mapping',\n",
    "                # 'repo_22_2':'repo_22_2',\n",
    "                # 'repo_22_3':'repo_22_3',\n",
    "                'time_of_registration':'Platform Reg Time',\n",
    "                'overall_percent_complete':'CEDAR Form %',\n",
    "                'repository_name' : 'Repo per Platform',\n",
    "                'archived':'Archived',\n",
    "                # 'heal_funded':'HEAL-Related'\n",
    "                }\n",
    "ctn_fields_platform = create_mysql_subset(ctn_data, extra_fields=['hdp_id'])\n",
    "## Edit pi name\n",
    "ctn_fields_platform['PI(s)'].fillna('', inplace=True)\n",
    "ctn_fields_platform['PI(s)'] = [ k.translate(str.maketrans(',', ';', \"[]\\'\")) for k in  ctn_fields_platform['PI(s)']]\n",
    "\n",
    "ctn_fields_platform['key'] = ctn_fields_platform['hdp_id']\n",
    "ctn_fields_platform['study_hdp_id'] = ctn_fields_platform['hdp_id']\n",
    "ctn_fields_platform['Network'] = ['CTN']*len(ctn_fields_platform)\n",
    "## Combine the data to the other data set\n",
    "all_data = pd.concat([combined_data_ph1, ctn_fields_platform])\n",
    "all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = all_data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "study_type\n",
      "HDP           1160\n",
      "CTN             40\n",
      "APPLIDONLY      38\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Most Recent Appl_ID', 'HDP appl_ID', 'key', 'Research Focus',\n",
       "       'Research Program', 'DAI Import Status', 'HEAL-Related', 'Project #',\n",
       "       'Title', 'Contact PI', 'Administering IC', 'NIH PO', 'Institution(s)',\n",
       "       'PI(s)', 'City', 'State', 'Activity Code', 'Award Type', 'Award Year',\n",
       "       'Total Funded', 'Summary', 'SBIR/STTR', 'Project Start', 'Project End',\n",
       "       'Reporter Link', 'Repo Mapping', 'repo_22_2', 'repo_22_3',\n",
       "       'Platform Reg Time', 'CEDAR Form %', 'Repo per Platform', 'Archived',\n",
       "       'Network', 'Contact Email', 'Location', 'study_type'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create a column named \"Location\"dd\n",
    "from datetime import datetime\n",
    "combined_data['study_type'] = [ 'CTN' if m.startswith('CTN') else ('APPLIDONLY' if pd.isna(k) else 'HDP') for (m,k) in combined_data[['Project #', 'study_hdp_id_appl']].values]\n",
    "\n",
    "combined_data['City'] = combined_data[['City']].fillna('')\n",
    "combined_data['State'] = combined_data[['State']].fillna('')\n",
    "combined_data['Location'] = [c+\",\"+s for (c,s) in combined_data[['City', \"State\"]].values]\n",
    "\n",
    "combined_data['Project Start'] = pd.to_datetime(combined_data['Project Start'], format='%Y-%m-%d', errors='coerce').dt.date\n",
    "combined_data['Project End'] = pd.to_datetime(combined_data['Project End'], format='%Y-%m-%d', errors='coerce').dt.date\n",
    "combined_data['Platform Reg Time'] = pd.to_datetime(combined_data['Platform Reg Time'], utc=True).dt.date\n",
    "\n",
    "\n",
    "combined_data['Archived'] = [a if a=='archived' else '' for a in combined_data['Archived']]\n",
    "combined_data['HEAL-Related'] = ['Y' if ((p is not 'CTN' ) and (pd.isna(a))) else '' for a in combined_data['HEAL-Related']]\n",
    "combined_data['SBIR/STTR'] = [t if t=='SBIR/STTR' else '' for t in combined_data['SBIR/STTR']]\n",
    "\n",
    "print(combined_data.study_type.value_counts())\n",
    "\n",
    "## Rename a few of the other columns:\n",
    "combined_data.rename(columns={'study_most_recent_appl':'Most Recent Appl_ID', 'study_hdp_id_appl':'HDP appl_ID'}, inplace=True)\n",
    "combined_data.drop(columns=['study_hdp_id', 'hdp_id'], inplace=True)\n",
    "\n",
    "combined_data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Find what's in Monday.com board, but not in mysql extract\n",
    "# Mark these entries for deletion, and these would have to be deleted manually on Monday.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making sure uniqueness of key values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    1238.0\n",
       "mean        1.0\n",
       "std         0.0\n",
       "min         1.0\n",
       "25%         1.0\n",
       "50%         1.0\n",
       "75%         1.0\n",
       "max         1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.index.name = 'index'\n",
    "combined_data.to_excel(input_dir/\"MondayBoard_Update.xlsx\")\n",
    "\n",
    "print(\"Making sure uniqueness of key values\")\n",
    "key_counts = combined_data.groupby('key').size()\n",
    "key_counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_data_subset = combined_data[ combined_data['Most Recent Appl_ID'].isin(monday_board['Most Recent Appl_ID']) | combined_data['key'].isin(monday_board['Name'])].drop_duplicates()\n",
    "# combined_data_subset = combined_data_subset[ ~pd.isna(combined_data_subset['Most Recent Appl_ID']) ]\n",
    "# print(len(combined_data_subset))\n",
    "# combined_data_subset.to_excel(input_dir/\"MondayBoard_Update_Step2.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(monday_board))\n",
    "# missing_monday = combined_data_subset[~combined_data_subset.key.isin(monday_board.Name)]\n",
    "# print(len(missing_monday))\n",
    "# print(missing_monday.key)\n",
    "\n",
    "# ## Did all the most_recent_appl_ids make it into the subset\n",
    "# print(f\"Number of most recent applids on Monday: {len(monday_board['Most Recent Appl_ID'].drop_duplicates())}, in subset: {len(combined_data_subset['Most Recent Appl_ID'].drop_duplicates())}\")\n",
    "# print(monday_board[ ~monday_board['Most Recent Appl_ID'].isin(combined_data_subset['Most Recent Appl_ID']) ]['Most Recent Appl_ID'])\n",
    "\n",
    "# ## What is in Monday that is not in this combined dataset?\n",
    "# missing_frommonday_inextract = monday_board[~monday_board.Name.isin(combined_data_subset.key)]\n",
    "# print(len(missing_frommonday_inextract))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******************\n",
    "*******************\n",
    "DEBUG CODE BELOW\n",
    "*******************\n",
    "*******************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Most Recent Appl_ID</th>\n",
       "      <th>HDP appl_ID</th>\n",
       "      <th>key</th>\n",
       "      <th>Research Focus</th>\n",
       "      <th>Research Program</th>\n",
       "      <th>DAI Import Status</th>\n",
       "      <th>HEAL-Related</th>\n",
       "      <th>Project #</th>\n",
       "      <th>Title</th>\n",
       "      <th>Contact PI</th>\n",
       "      <th>...</th>\n",
       "      <th>repo_22_2</th>\n",
       "      <th>repo_22_3</th>\n",
       "      <th>Platform Reg Time</th>\n",
       "      <th>CEDAR Form %</th>\n",
       "      <th>Repo per Platform</th>\n",
       "      <th>Archived</th>\n",
       "      <th>Network</th>\n",
       "      <th>Contact Email</th>\n",
       "      <th>Location</th>\n",
       "      <th>study_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>10593312</td>\n",
       "      <td>10601172</td>\n",
       "      <td>HDP00889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>3R24DA055306-02S1</td>\n",
       "      <td>Wake Forest IMPOWR Dissemination Education and...</td>\n",
       "      <td>ADAMS, MEREDITH C. B.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-07-26</td>\n",
       "      <td>5.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>meradams@wakehealth.edu</td>\n",
       "      <td>WINSTON-SALEM,NC</td>\n",
       "      <td>HDP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Most Recent Appl_ID HDP appl_ID       key Research Focus  \\\n",
       "index                                                            \n",
       "660              10593312    10601172  HDP00889            NaN   \n",
       "\n",
       "      Research Program DAI Import Status HEAL-Related          Project #  \\\n",
       "index                                                                      \n",
       "660                NaN               NaN            Y  3R24DA055306-02S1   \n",
       "\n",
       "                                                   Title  \\\n",
       "index                                                      \n",
       "660    Wake Forest IMPOWR Dissemination Education and...   \n",
       "\n",
       "                  Contact PI  ... repo_22_2 repo_22_3 Platform Reg Time  \\\n",
       "index                         ...                                         \n",
       "660    ADAMS, MEREDITH C. B.  ...       NaN       NaN        2022-07-26   \n",
       "\n",
       "      CEDAR Form % Repo per Platform Archived Network  \\\n",
       "index                                                   \n",
       "660            5.8               NaN              NaN   \n",
       "\n",
       "                 Contact Email          Location  study_type  \n",
       "index                                                         \n",
       "660    meradams@wakehealth.edu  WINSTON-SALEM,NC         HDP  \n",
       "\n",
       "[1 rows x 36 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data[combined_data['key']=='HDP00889'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_cols = ['Most Recent Appl_ID', 'HDP appl_ID', 'Contact Email', 'Network']\n",
    "\n",
    "comparison_df = pd.merge(monday_board[['Name'] +comparison_cols ], combined_data[['key'] + comparison_cols], left_on = 'Name', right_on='key').drop_duplicates()\n",
    "comparison_df.to_csv(input_dir/\"comparison.csv\", index=False)\n",
    "comparison_df.to_excel(input_dir/\"comparison.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'Most Recent Appl_ID_x', 'HDP appl_ID_x', 'Contact Email_x',\n",
       "       'Network_x', 'key', 'Most Recent Appl_ID_y', 'HDP appl_ID_y',\n",
       "       'Contact Email_y', 'Network_y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_most_recent_appl</th>\n",
       "      <th>pi_email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>9901704</td>\n",
       "      <td>jhambm@upmc.edu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    study_most_recent_appl         pi_email\n",
       "881                9901704  jhambm@upmc.edu"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_emails_df_updated[ pi_emails_df_updated.study_most_recent_appl=='9901704']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appl_id</th>\n",
       "      <th>res_net</th>\n",
       "      <th>res_net_override_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>9908734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      appl_id res_net  res_net_override_flag\n",
       "1486  9908734     NaN                      0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_df[resnet_df.appl_id=='9908734']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.to_excel(input_dir/\"test.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/hinashah/Documents/HEAL/MondayFolderUpdate_202406/STEP1_MondayUpdate.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m expected_study_groups \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_dir\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSTEP1_MondayUpdate.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlow_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m study_groups_to_keep \u001b[38;5;241m=\u001b[39m expected_study_groups[expected_study_groups\u001b[38;5;241m.\u001b[39mkeep_count\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mmost_recent_study_group\u001b[38;5;241m.\u001b[39mdrop_duplicates()\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      4\u001b[0m study_groups \u001b[38;5;241m=\u001b[39m monday_board[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTEMP: most_recent_study_group\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/hinashah/Documents/HEAL/MondayFolderUpdate_202406/STEP1_MondayUpdate.csv'"
     ]
    }
   ],
   "source": [
    "expected_study_groups = pd.read_csv(input_dir/\"STEP1_MondayUpdate.csv\", low_memory=False)\n",
    "study_groups_to_keep = expected_study_groups[expected_study_groups.keep_count==1].most_recent_study_group.drop_duplicates().values\n",
    "\n",
    "study_groups = monday_board['TEMP: most_recent_study_group']\n",
    "missing_studygroups = [k for k in study_groups_to_keep if k not in study_groups.values]\n",
    "print(len(missing_studygroups))\n",
    "missing_studygroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['study_hdp_id', 'study_most_recent_appl', 'study_hdp_id_appl', 'key',\n",
       "       'Research Focus', 'TEMP_Res_Prog', 'Data Mgmt', 'DAI Import Status',\n",
       "       'Network', 'Is Heal Funded or Relevant', 'Project #', 'Title',\n",
       "       'Conctact PI', 'Administering IC', 'NIH PO', 'Institution(s)', 'PI(s)',\n",
       "       'City', 'State', 'Activity Code', 'Award Type', 'Total Funded',\n",
       "       'Summary', 'Project Start', 'Project End', 'Reporter Link',\n",
       "       'Repo Mapping', 'repo_22_2', 'repo_22_3', 'Platform Reg Time',\n",
       "       'CEDAR Form %', 'Repo per Platform', 'Archived on Platform?', 'hdp_id',\n",
       "       'Contact Email', 'Location'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
