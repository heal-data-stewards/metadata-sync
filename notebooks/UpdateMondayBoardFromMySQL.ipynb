{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aWIlRIFRym-"
      },
      "source": [
        "# HEAL Monday Studies Board Update pipeline\n",
        "\n",
        "Jupyter Notebook to follow the SOP for update the HEAL Monday Board. \n",
        "The notebook can be used for either step by step exploration, or running from a service like Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSmDQIuMSnpN",
        "outputId": "ad1080e5-971a-45a8-a49f-2c4cbbb89616"
      },
      "outputs": [],
      "source": [
        "## If running on Google Colab, run this cell to mount Google Drive to access files on Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbhR65sIRym_",
        "outputId": "a39d83d0-25cb-4a7f-fcb7-d2d8b7ed00df"
      },
      "outputs": [],
      "source": [
        "## If running from Google Colab, might need to install this library\n",
        "!pip install xlsxwriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "n2fU7AmORynA"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import logging\n",
        "from pathlib import Path\n",
        "sys.path.append('../scripts/')\n",
        "import monday_board_update\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oBnrQDepRynA"
      },
      "outputs": [],
      "source": [
        "## Set this to the directory where:\n",
        "## 1- Monday Studies board has been exported.\n",
        "## 2- All relevant tables from MySql database for HEAL have been exported as a csv to.\n",
        "# input_dir = Path(\"/pat/to/data/dir\")\n",
        "input_dir = Path(\"/Users/hinashah/Documents/HEAL/MondayUpdate_Feb2026\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Setup logger\n",
        "logging.basicConfig(\n",
        "        level=logging.DEBUG,\n",
        "        format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
        "        filename= input_dir / \"report-log.txt\",\n",
        "    )\n",
        "logging.getLogger().addHandler(logging.StreamHandler(sys.stdout))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---- STEP 1: Looking at Study Lookup Table\n",
            "Number of entries in study lookup table: 2660\n",
            "Number of distinct values in --appl_id--: 2626\n",
            "---- NA count: 0\n",
            "Number of distinct values in --xstudy_id--: 1623\n",
            "---- NA count: 0\n",
            "Number of distinct values in --study_hdp_id--: 1497\n",
            "---- NA count: 189\n",
            "Number of distinct values in --study_hdp_id_appl--: 1475\n",
            "---- NA count: 189\n",
            "Number of distinct values in --study_most_recent_appl--: 1602\n",
            "---- NA count: 0\n",
            "Number of distinct values in --study_first_appl--: 1601\n",
            "---- NA count: 0\n",
            "Number of distinct values in --compound_key--: 2648\n",
            "---- NA count: 0\n"
          ]
        }
      ],
      "source": [
        "logging.info(\"---- STEP 1: Looking at Study Lookup Table\")\n",
        "gt_file = monday_board_update.import_study_lookup_table(input_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---- STEP 2: Importing Monday Studies Board\n",
            "[PosixPath('/Users/hinashah/Documents/HEAL/MondayUpdate_Feb2026/HEAL_Studies_1770661804_Deletions.xlsx'), PosixPath('/Users/hinashah/Documents/HEAL/MondayUpdate_Feb2026/HEAL_Studies_1770389317.xlsx')]\n",
            "Index(['Name', 'Most Recent Appl_ID', 'HDP appl_ID', 'Project #', 'Archived',\n",
            "       'HEAL-Related', 'Data Type', 'Research Focus', 'Research Program',\n",
            "       'Research Network', 'Title', 'Contact PI', 'Contact Email',\n",
            "       'Administering IC', 'NIH PO', 'NIH PO Email', 'Institution(s)', 'PI(s)',\n",
            "       'Location', 'Activity Code', 'Award Type', 'Award Year', 'Total Funded',\n",
            "       'Summary', 'Project Start', 'Project End', 'Reporter Link', 'SBIR/STTR',\n",
            "       'Data Engagement', 'Repo per Platform', 'Platform Reg Time',\n",
            "       'CEDAR Form %', 'Creation Log', 'study_type',\n",
            "       '\"Get the Data\" Engagement Board', 'VLMD Status', 'DD Tracker',\n",
            "       'Checklist Exempt', 'Do not Engage', 'link to Data Dictionary Tracker',\n",
            "       '_tmp'],\n",
            "      dtype='object')\n",
            "Number of records on Monday Board: 34\n"
          ]
        }
      ],
      "source": [
        "logging.info(\"---- STEP 2: Importing Monday Studies Board\")\n",
        "monday_board = monday_board_update.import_monday_board(input_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---- STEP 3: Compare lookup table and Monday Board\n",
            "Number records from Monday already in lookup table: 0\n",
            "Number records from Monday that are not in lookup table (Consider these as discrepancies **Investigate**): 34\n",
            "Number records from lookup table that are not on Monday (Potentially new entries): 1623\n",
            "Entries in Monday that are not in lookup table\n",
            "                 Name Most Recent Appl_ID HDP appl_ID  \\\n",
            "0            HDP01518                   -           -   \n",
            "1            HDP01519                   -           -   \n",
            "2            HDP01514                   -           -   \n",
            "3            HDP01515                   -           -   \n",
            "4            HDP01517                   -           -   \n",
            "5            HDP01516                   -           -   \n",
            "6            HDP01513                   -           -   \n",
            "11  10428343_HDP00882                 NaN         NaN   \n",
            "12  10488140_HDP00883                 NaN         NaN   \n",
            "13       9673173_none                 NaN         NaN   \n",
            "14       9769689_none                 NaN         NaN   \n",
            "19           10934856            10934856           -   \n",
            "20           11129951            11129951           -   \n",
            "21           10881322            10881322           -   \n",
            "22           11009694            11009694           -   \n",
            "23           11044441            11044441           -   \n",
            "24           11046758            11046758           -   \n",
            "25           10936304            10936304           -   \n",
            "26           10936429            10936429           -   \n",
            "27           11167995            11167995           -   \n",
            "28           11134921            11134921           -   \n",
            "29           10935531            10935531           -   \n",
            "30           11141362            11141362           -   \n",
            "31           10818491            10818491           -   \n",
            "32           10684152            10684152           -   \n",
            "33           10663090            10663090           -   \n",
            "34           10885960            10885960           -   \n",
            "35           10744466            10744466           -   \n",
            "36           10920413            10920413           -   \n",
            "37           11055122            11055122           -   \n",
            "38           11302198            11302198           -   \n",
            "39           11055938            11055938           -   \n",
            "40           11062103            11062103           -   \n",
            "41           11059453            11059453           -   \n",
            "\n",
            "                               Project # Archived HEAL-Related Data Type  \\\n",
            "0                        1U2CDA050098-01        n            Y         -   \n",
            "1                        1U2CDA050098-01        n            Y         -   \n",
            "2                            ICPSR-30122        n            Y         -   \n",
            "3                            ICPSR-34945        n            Y         -   \n",
            "4                            ICPSR-38502        n            Y         -   \n",
            "5                            ICPSR-38503        n            Y         -   \n",
            "6                             ICPSR-4256        n            Y         -   \n",
            "11             75N95020P00589-P00001-0-1      NaN          NaN       NaN   \n",
            "12  75N95019D00026-P00003-759501900088-1      NaN          NaN       NaN   \n",
            "13                       5U24HD095254-02      NaN          NaN       NaN   \n",
            "14                       5R01DE027454-02      NaN          NaN       NaN   \n",
            "19                       1T90AR085527-01        n            N         -   \n",
            "20                       1R90AR085802-01        n            N         -   \n",
            "21                       1R61DA060426-01        n            N         -   \n",
            "22                       1R21DA061660-01        n            N         -   \n",
            "23                       1UG3DA062088-01        n            N         -   \n",
            "24                       1R01DA062152-01        n            N         -   \n",
            "25                       1T90DA062773-01        n            N         -   \n",
            "26                       1T90HD118400-01        n            N         -   \n",
            "27                       1R90HD118650-01        n            N         -   \n",
            "28                       1R90NR021799-01        n            N         -   \n",
            "29                       1T90NS138001-01        n            N         -   \n",
            "30                       1R90NS143074-01        n            N         -   \n",
            "31                       5U24HD036801-27        n            Y         -   \n",
            "32                       5U24HD095254-07        n            Y         -   \n",
            "33                       5U19MH121738-05        n            Y         -   \n",
            "34                       5R01NS045594-19        n            Y         -   \n",
            "35                       2U2COD023375-08        n            Y         -   \n",
            "36                       5U24TR004314-03        n            Y         -   \n",
            "37                       2UG1DA013732-26        n            N         -   \n",
            "38                     3UG1DA015831-24S1        n            N         -   \n",
            "39                       2UG1DA049435-06        n            N         -   \n",
            "40                       2UG1DA049436-06        n            N         -   \n",
            "41                       2UG1DA049468-06        n            N         -   \n",
            "\n",
            "                                       Research Focus  \\\n",
            "0                                                   -   \n",
            "1                                                   -   \n",
            "2                                                   -   \n",
            "3                                                   -   \n",
            "4                                                   -   \n",
            "5                                                   -   \n",
            "6                                                   -   \n",
            "11                                                NaN   \n",
            "12                                                NaN   \n",
            "13  Enhanced Outcomes for Infants and Children Exp...   \n",
            "14  Preclinical and Translational Research in Pain...   \n",
            "19  Training the Next Generation of Researchers in...   \n",
            "20  Training the Next Generation of Researchers in...   \n",
            "21  New Strategies to Prevent and Treat Opioid Add...   \n",
            "22                             Cross-Cutting Research   \n",
            "23  Novel Therapeutic Options for Opioid Use Disor...   \n",
            "24  Enhanced Outcomes for Infants and Children Exp...   \n",
            "25  Training the Next Generation of Researchers in...   \n",
            "26  Training the Next Generation of Researchers in...   \n",
            "27  Training the Next Generation of Researchers in...   \n",
            "28  Training the Next Generation of Researchers in...   \n",
            "29  Training the Next Generation of Researchers in...   \n",
            "30  Training the Next Generation of Researchers in...   \n",
            "31                                                  -   \n",
            "32                                                  -   \n",
            "33                                                  -   \n",
            "34                                                  -   \n",
            "35                                                  -   \n",
            "36                                                  -   \n",
            "37  Translation of Research to Practice for the Tr...   \n",
            "38  Translation of Research to Practice for the Tr...   \n",
            "39  Translation of Research to Practice for the Tr...   \n",
            "40  Translation of Research to Practice for the Tr...   \n",
            "41  Translation of Research to Practice for the Tr...   \n",
            "\n",
            "                                     Research Program Research Network  ...  \\\n",
            "0                                                   -                -  ...   \n",
            "1                                                   -                -  ...   \n",
            "2                                                   -                -  ...   \n",
            "3                                                   -                -  ...   \n",
            "4                                                   -                -  ...   \n",
            "5                                                   -                -  ...   \n",
            "6                                                   -                -  ...   \n",
            "11                                                NaN              NaN  ...   \n",
            "12                                                NaN              NaN  ...   \n",
            "13                                                NaN          ACT NOW  ...   \n",
            "14                                                NaN              NaN  ...   \n",
            "19  Training the Next Generation of Researchers in...                -  ...   \n",
            "20  Training the Next Generation of Researchers in...                -  ...   \n",
            "21                                                  -                -  ...   \n",
            "22                                                  -                -  ...   \n",
            "23  Focusing Medication Development to Prevent and...                -  ...   \n",
            "24                                                  -                -  ...   \n",
            "25  Training the Next Generation of Researchers in...                -  ...   \n",
            "26  Training the Next Generation of Researchers in...                -  ...   \n",
            "27  Training the Next Generation of Researchers in...                -  ...   \n",
            "28  Training the Next Generation of Researchers in...                -  ...   \n",
            "29  Training the Next Generation of Researchers in...                -  ...   \n",
            "30  Training the Next Generation of Researchers in...                -  ...   \n",
            "31                                                  -             MFMU  ...   \n",
            "32                                                  -          ACT NOW  ...   \n",
            "33                                                  -                -  ...   \n",
            "34                                                  -                -  ...   \n",
            "35                                                  -          ACT NOW  ...   \n",
            "36                                                  -                -  ...   \n",
            "37  Enhancing the National Drug Abuse Treatment Cl...                -  ...   \n",
            "38  Enhancing the National Drug Abuse Treatment Cl...                -  ...   \n",
            "39  Enhancing the National Drug Abuse Treatment Cl...                -  ...   \n",
            "40  Enhancing the National Drug Abuse Treatment Cl...                -  ...   \n",
            "41  Enhancing the National Drug Abuse Treatment Cl...                -  ...   \n",
            "\n",
            "   CEDAR Form %                      Creation Log  study_type  \\\n",
            "0             0    Hina Shah Sep 26, 2025 4:08 PM         HDP   \n",
            "1             0    Hina Shah Sep 26, 2025 4:08 PM         HDP   \n",
            "2             0    Hina Shah Sep 26, 2025 4:08 PM         HDP   \n",
            "3             0    Hina Shah Sep 26, 2025 4:08 PM         HDP   \n",
            "4             0    Hina Shah Sep 26, 2025 4:08 PM         HDP   \n",
            "5             0    Hina Shah Sep 26, 2025 4:08 PM         HDP   \n",
            "6             0    Hina Shah Sep 26, 2025 4:08 PM         HDP   \n",
            "11          NaN  Kathy Jooss May 4, 2023 11:25 AM         NaN   \n",
            "12          NaN  Kathy Jooss May 4, 2023 11:25 AM         NaN   \n",
            "13          NaN  Kathy Jooss Nov 29, 2021 8:34 AM         NaN   \n",
            "14          NaN  Kathy Jooss Nov 29, 2021 7:59 AM         NaN   \n",
            "19          NaN    Sarah Myer Jan 8, 2025 3:37 PM  APPLIDONLY   \n",
            "20          NaN    Sarah Myer Jan 8, 2025 3:37 PM  APPLIDONLY   \n",
            "21          NaN    Sarah Myer Jan 8, 2025 3:38 PM  APPLIDONLY   \n",
            "22          NaN    Sarah Myer Jan 8, 2025 3:35 PM  APPLIDONLY   \n",
            "23          NaN    Sarah Myer Jan 8, 2025 3:35 PM  APPLIDONLY   \n",
            "24          NaN    Sarah Myer Jan 8, 2025 3:35 PM  APPLIDONLY   \n",
            "25          NaN    Sarah Myer Jan 8, 2025 3:35 PM  APPLIDONLY   \n",
            "26          NaN    Sarah Myer Jan 8, 2025 3:35 PM  APPLIDONLY   \n",
            "27          NaN    Sarah Myer Jan 8, 2025 3:35 PM  APPLIDONLY   \n",
            "28          NaN    Sarah Myer Jan 8, 2025 3:36 PM  APPLIDONLY   \n",
            "29          NaN    Sarah Myer Jan 8, 2025 3:37 PM  APPLIDONLY   \n",
            "30          NaN    Sarah Myer Jan 8, 2025 3:37 PM  APPLIDONLY   \n",
            "31          NaN    Hina Shah May 23, 2025 1:38 PM  APPLIDONLY   \n",
            "32          NaN    Hina Shah May 23, 2025 1:38 PM  APPLIDONLY   \n",
            "33          NaN    Hina Shah May 23, 2025 1:38 PM  APPLIDONLY   \n",
            "34          NaN    Hina Shah May 23, 2025 1:38 PM  APPLIDONLY   \n",
            "35          NaN    Hina Shah May 23, 2025 1:38 PM  APPLIDONLY   \n",
            "36          NaN    Hina Shah May 23, 2025 1:38 PM  APPLIDONLY   \n",
            "37          NaN    Hina Shah Sep 26, 2025 4:08 PM  APPLIDONLY   \n",
            "38          NaN    Hina Shah Sep 26, 2025 4:08 PM  APPLIDONLY   \n",
            "39          NaN    Hina Shah Sep 26, 2025 4:08 PM  APPLIDONLY   \n",
            "40          NaN    Hina Shah Sep 26, 2025 4:08 PM  APPLIDONLY   \n",
            "41          NaN    Hina Shah Sep 26, 2025 4:08 PM  APPLIDONLY   \n",
            "\n",
            "   \"Get the Data\" Engagement Board VLMD Status DD Tracker Checklist Exempt  \\\n",
            "0                              NaN         NaN   HDP01518                N   \n",
            "1                              NaN         NaN   HDP01519                N   \n",
            "2                              NaN         NaN   HDP01514                N   \n",
            "3                              NaN         NaN   HDP01515                N   \n",
            "4                              NaN         NaN   HDP01517                N   \n",
            "5                              NaN         NaN   HDP01516                N   \n",
            "6                              NaN         NaN   HDP01513                N   \n",
            "11                             NaN         NaN        NaN              NaN   \n",
            "12                             NaN         NaN        NaN              NaN   \n",
            "13                             NaN         NaN        NaN              NaN   \n",
            "14                             NaN         NaN        NaN              NaN   \n",
            "19                             NaN         NaN        NaN                Y   \n",
            "20                             NaN         NaN        NaN                Y   \n",
            "21                             NaN         NaN        NaN                Y   \n",
            "22                             NaN         NaN        NaN                Y   \n",
            "23                             NaN         NaN        NaN                Y   \n",
            "24                             NaN         NaN        NaN                Y   \n",
            "25                             NaN         NaN        NaN                Y   \n",
            "26                             NaN         NaN        NaN                Y   \n",
            "27                             NaN         NaN        NaN                Y   \n",
            "28                             NaN         NaN        NaN                Y   \n",
            "29                             NaN         NaN        NaN                Y   \n",
            "30                             NaN         NaN        NaN                Y   \n",
            "31                             NaN         NaN        NaN                N   \n",
            "32                             NaN         NaN        NaN                N   \n",
            "33                             NaN         NaN        NaN                N   \n",
            "34                             NaN         NaN        NaN                N   \n",
            "35                             NaN         NaN        NaN                N   \n",
            "36                             NaN         NaN        NaN                N   \n",
            "37                             NaN         NaN        NaN                N   \n",
            "38                             NaN         NaN        NaN                N   \n",
            "39                             NaN         NaN        NaN                N   \n",
            "40                             NaN         NaN        NaN                N   \n",
            "41                             NaN         NaN        NaN                N   \n",
            "\n",
            "   Do not Engage link to Data Dictionary Tracker _tmp  \n",
            "0              N                             NaN  NaN  \n",
            "1              N                             NaN  NaN  \n",
            "2              N                             NaN  NaN  \n",
            "3              N                             NaN  NaN  \n",
            "4              N                             NaN  NaN  \n",
            "5              N                             NaN  NaN  \n",
            "6              N                             NaN  NaN  \n",
            "11           NaN                             NaN  NaN  \n",
            "12           NaN                             NaN  NaN  \n",
            "13           NaN                             NaN  NaN  \n",
            "14           NaN                             NaN  NaN  \n",
            "19             Y                             NaN  NaN  \n",
            "20             Y                             NaN  NaN  \n",
            "21             Y                             NaN  NaN  \n",
            "22             Y                             NaN  NaN  \n",
            "23             Y                             NaN  NaN  \n",
            "24             Y                             NaN  NaN  \n",
            "25             Y                             NaN  NaN  \n",
            "26             Y                             NaN  NaN  \n",
            "27             Y                             NaN  NaN  \n",
            "28             Y                             NaN  NaN  \n",
            "29             Y                             NaN  NaN  \n",
            "30             Y                             NaN  NaN  \n",
            "31             N                             NaN  NaN  \n",
            "32             N                             NaN  NaN  \n",
            "33             N                             NaN  NaN  \n",
            "34             N                             NaN  NaN  \n",
            "35             N                             NaN  NaN  \n",
            "36             N                             NaN  NaN  \n",
            "37             N                             NaN  NaN  \n",
            "38             N                             NaN  NaN  \n",
            "39             N                             NaN  NaN  \n",
            "40             N                             NaN  NaN  \n",
            "41             N                             NaN  NaN  \n",
            "\n",
            "[34 rows x 41 columns]\n"
          ]
        }
      ],
      "source": [
        "logging.info(\"---- STEP 3: Compare lookup table and Monday Board\")\n",
        "mondayboard_missingin_lookup, lookup_fields = monday_board_update.compare_study_loookup_monday(gt_file, monday_board)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# def get_unique_values(df:pd.DataFrame, col_name:str='appl_id'):\n",
        "#     if col_name in df.columns:\n",
        "#         return df[ ~pd.isna(df[col_name])][col_name].drop_duplicates()\n",
        "#     return None\n",
        "\n",
        "# convert_dict = {'appl_id':str}\n",
        "# resnet_df = pd.read_csv(input_dir/\"research_networks.csv\", low_memory=False, dtype=convert_dict)\n",
        "# logging.info(f\"Research Network table has: {len(resnet_df)} entrie, with {len(get_unique_values(resnet_df))} appl_ids\")\n",
        "# print(resnet_df.columns)\n",
        "# appl_ids = gt_file[['appl_id', 'study_most_recent_appl']].drop_duplicates()\n",
        "# print(len(appl_ids))\n",
        "# resnet_added = pd.merge(appl_ids, resnet_df[['appl_id', 'res_net']], how = 'left', left_on='appl_id', right_on='appl_id' )\n",
        "# print(len(resnet_added))\n",
        "# resnet_most_recent_appl_id = resnet_added[~pd.isna(resnet_added.res_net)][['study_most_recent_appl', 'res_net']]\n",
        "# resnet_added_updated = pd.merge(appl_ids, resnet_most_recent_appl_id, how='left', left_on='study_most_recent_appl', right_on='study_most_recent_appl')\n",
        "# resnet_added_updated.to_csv(\"/tmp/tmp_resnet_updated.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---- STEP 4: Importing tables from MySQL and combining relevant information\n",
            "Awards table has: 2439 entries, with 2439 appl_ids\n",
            "*** Combining the two reporter tables\n",
            "2439\n",
            "489\n",
            "2928\n",
            "Reporter table has: 2928 entries, with 2928 appl_ids\n",
            "Platform generated table has: 1680 entries, with 1608 appl_ids\n",
            "Platform table has 1608 unique HDP IDs\n",
            "Repo mapping table has: 1748 entries, with 1748 appl_ids\n",
            "Research Network table has: 2439 entries, with 2439 appl_ids\n",
            "Engagment Flags table has: 2626 entries, with 2626 appl_ids\n",
            "PO Emails table has: 420 entries, with 420 appl_ids\n",
            "--- Wrangling PI Emails\n",
            "ALL PI emails associated with a project (identified by most_recent_appl)\n",
            "      study_most_recent_appl               pi_email_latest\n",
            "1                   9755001             kwatkins@rand.org\n",
            "3                  10088639               damico@rand.org\n",
            "4                  11195709         acfernan@med.umich.ed\n",
            "6                  11196080               fqeadan@luc.edu\n",
            "8                   9869480             LYNN.DEBAR@KP.ORG\n",
            "...                     ...                           ...\n",
            "2615               11193636         monica.kraft@mssm.edu\n",
            "2616               11195200  lucila.ohno-machado@yale.edu\n",
            "2617               11193592        szuchner@med.miami.edu\n",
            "2623               11179276       danny.benjamin@duke.edu\n",
            "2626               11167601       william.becker@yale.edu\n",
            "\n",
            "[1394 rows x 2 columns]\n",
            "Statistics on number of emails per project:: \n",
            " count    1306.000000\n",
            "mean        1.067381\n",
            "std         0.256816\n",
            "min         1.000000\n",
            "25%         1.000000\n",
            "50%         1.000000\n",
            "75%         1.000000\n",
            "max         3.000000\n",
            "dtype: float64 \n",
            "Emails that were kept for each project when there's only one email available, or when email is available for the most recent award (study_most_recent_appl)\n",
            "     study_most_recent_appl                      pi_email\n",
            "0                   9860408                              \n",
            "1                   9755001             kwatkins@rand.org\n",
            "3                  10088639               damico@rand.org\n",
            "4                  11195709         acfernan@med.umich.ed\n",
            "6                  11196080               fqeadan@luc.edu\n",
            "...                     ...                           ...\n",
            "2616               11195200  lucila.ohno-machado@yale.edu\n",
            "2617               11193592        szuchner@med.miami.edu\n",
            "2618               10021038                              \n",
            "2623               11179276       danny.benjamin@duke.edu\n",
            "2626               11167601       william.becker@yale.edu\n",
            "\n",
            "[1602 rows x 2 columns]\n",
            "Adding any Monday Board emails when emails missing from MySql. Data looks like: \n",
            "     study_most_recent_appl                      pi_email Contact Email  \\\n",
            "0                   9860408                                           -   \n",
            "1                   9755001             kwatkins@rand.org             -   \n",
            "2                  10088639               damico@rand.org             -   \n",
            "3                  11195709         acfernan@med.umich.ed             -   \n",
            "4                  11196080               fqeadan@luc.edu             -   \n",
            "...                     ...                           ...           ...   \n",
            "1597               11195200  lucila.ohno-machado@yale.edu             -   \n",
            "1598               11193592        szuchner@med.miami.edu             -   \n",
            "1599               10021038                                           -   \n",
            "1600               11179276       danny.benjamin@duke.edu             -   \n",
            "1601               11167601       william.becker@yale.edu             -   \n",
            "\n",
            "                  pi_email_updated  \n",
            "0                                   \n",
            "1                kwatkins@rand.org  \n",
            "2                  damico@rand.org  \n",
            "3            acfernan@med.umich.ed  \n",
            "4                  fqeadan@luc.edu  \n",
            "...                            ...  \n",
            "1597  lucila.ohno-machado@yale.edu  \n",
            "1598        szuchner@med.miami.edu  \n",
            "1599                                \n",
            "1600       danny.benjamin@duke.edu  \n",
            "1601       william.becker@yale.edu  \n",
            "\n",
            "[1602 rows x 4 columns]\n",
            "---- STEP 5: Gathering relevant data fields from MySQL tables\n",
            "Number of fields from lookup table: 1623\n",
            "Number of fields after adding reporter table fields: 1623\n",
            "Number of fields after adding awards table fields: 1623\n",
            "Number of fields after adding Platform MDS table fields: 1623\n",
            "Number of fields after adding research network table fields: 1623\n",
            "Number of fields after adding engagegment flag table fields: 1623\n",
            "Number of fields after adding PO Emai fields: 1623\n",
            "Number of fields after adding PI Emails: 1623\n",
            "Total entries in this combined dataset: 1623\n"
          ]
        }
      ],
      "source": [
        "logging.info(\"---- STEP 4: Importing tables from MySQL and combining relevant information\")\n",
        "combined_data_ph1 = monday_board_update.import_mysql_data(input_dir, gt_file, monday_board, lookup_fields)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---- STEP 5: Filling holes with MDS data\n"
          ]
        }
      ],
      "source": [
        "logging.info(\"---- STEP 5: Filling holes with MDS data\")\n",
        "combined_data_ph1 = monday_board_update.fill_in_holes_from_mds(input_dir, combined_data_ph1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---- STEP 6: Adding any CTN data from MDS\n",
            "Number of CTN entries found in Platform MDS 44\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/hinashah/code/HEAL/metadata-sync/notebooks/../scripts/monday_board_update.py:334: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ctn_data['project_title'] = ctn_data['project_title'].replace('0', '')\n"
          ]
        }
      ],
      "source": [
        "    ## Add CTN  data\n",
        "logging.info(\"---- STEP 6: Adding any CTN data from MDS\")\n",
        "ctn_fields_platform = monday_board_update.get_ctndata_from_mds(input_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---- STEP 7: Combining everything together\n",
            "------------ Preview of the final combined dataset ---------------\n",
            "     Activity Code Administering IC Archived Award Type  Award Year  \\\n",
            "0              U01            NIAAA     live          3      2019.0   \n",
            "1              R34            NIAAA     live          3      2019.0   \n",
            "2              R01            NIAAA     live          3      2020.0   \n",
            "3              R34            NIAAA     live          5      2025.0   \n",
            "4              R01            NIAAA     live          5      2025.0   \n",
            "...            ...              ...      ...        ...         ...   \n",
            "1318           NaN              NaN     live          0         NaN   \n",
            "1498           NaN              NaN     live          0         NaN   \n",
            "1499           NaN              NaN     live          0         NaN   \n",
            "1500           NaN              NaN     live          0         NaN   \n",
            "1501           NaN              NaN     live          0         NaN   \n",
            "\n",
            "      CEDAR Form %  Checklist Exempt          City          Contact Email  \\\n",
            "0              0.0               0.0      PORTLAND                          \n",
            "1              0.0               0.0  SANTA MONICA      kwatkins@rand.org   \n",
            "2              0.0               0.0  SANTA MONICA        damico@rand.org   \n",
            "3             80.8               1.0     ANN ARBOR  acfernan@med.umich.ed   \n",
            "4              0.0               1.0       MAYWOOD        fqeadan@luc.edu   \n",
            "...            ...               ...           ...                    ...   \n",
            "1318           0.0               NaN           NaN                    NaN   \n",
            "1498           0.0               NaN           NaN                    NaN   \n",
            "1499           0.0               NaN           NaN                    NaN   \n",
            "1500           0.0               NaN           NaN                    NaN   \n",
            "1501           0.0               NaN           NaN                    NaN   \n",
            "\n",
            "                    Contact PI  ...  \\\n",
            "0              NAGEL, BONNIE J  ...   \n",
            "1         WATKINS, KATHERINE E  ...   \n",
            "2        D'AMICO, ELIZABETH J.  ...   \n",
            "3     FERNANDEZ, ANNE CHRISTIE  ...   \n",
            "4                QEADAN, FARES  ...   \n",
            "...                        ...  ...   \n",
            "1318                       NaN  ...   \n",
            "1498                       NaN  ...   \n",
            "1499                       NaN  ...   \n",
            "1500                       NaN  ...   \n",
            "1501                       NaN  ...   \n",
            "\n",
            "                                                Summary  \\\n",
            "0     PROJECT SUMMARY. During young adulthood, drink...   \n",
            "1     PROJECT SUMMARY/ABSTRACT. Substance use disord...   \n",
            "2     Summary/Abstract. This administrative suppleme...   \n",
            "3     Opioid agonist therapies (i.e. buprenorphine a...   \n",
            "4     Project Summary/Abstract. The intersection of ...   \n",
            "...                                                 ...   \n",
            "1318  Adolescent outcomes of Post-operative opioid E...   \n",
            "1498  Effects of Semaglutide and Tirzepatide on Inci...   \n",
            "1499  Low-threshold Buprenorphine Treatment at Syrin...   \n",
            "1500  Evaluation of Tirzepatide as an Adjunct to Bup...   \n",
            "1501  EMS initiated Buprenorphine for Opioid Use Dis...   \n",
            "\n",
            "                                                  Title  Total Funded  \\\n",
            "0     National Consortium on Alcohol and Neurodevelo...       93429.0   \n",
            "1     Implementing Medication-Assisted Therapy for S...       99988.0   \n",
            "2     AOD Use Trajectories from Age 10 to 24: Multi-...       99999.0   \n",
            "3     Cultivating Recovery: A Pilot Study of Digital...      390000.0   \n",
            "4     Advancing Integrated Treatment for Co-Occurrin...      385000.0   \n",
            "...                                                 ...           ...   \n",
            "1318                                                NaN           0.0   \n",
            "1498                                                NaN           0.0   \n",
            "1499                                                NaN           0.0   \n",
            "1500                                                NaN           0.0   \n",
            "1501                                                NaN           0.0   \n",
            "\n",
            "      hdp_id_x  hdp_id_y       key study_hdp_id study_hdp_id_appl  \\\n",
            "0     HDP00632  HDP00632  HDP00632     HDP00632           9860408   \n",
            "1     HDP00696  HDP00696  HDP00696     HDP00696           9755001   \n",
            "2     HDP00509  HDP00509  HDP00509     HDP00509           9850412   \n",
            "3     HDP01356  HDP01356  HDP01356     HDP01356          10996795   \n",
            "4     HDP01380  HDP01380  HDP01380     HDP01380          11001407   \n",
            "...        ...       ...       ...          ...               ...   \n",
            "1318       NaN       NaN  HDP01324     HDP01324               NaN   \n",
            "1498       NaN       NaN  HDP01504     HDP01504               NaN   \n",
            "1499       NaN       NaN  HDP01505     HDP01505               NaN   \n",
            "1500       NaN       NaN  HDP01506     HDP01506               NaN   \n",
            "1501       NaN       NaN  HDP01507     HDP01507               NaN   \n",
            "\n",
            "     study_most_recent_appl    hdp_id  \n",
            "0                   9860408       NaN  \n",
            "1                   9755001       NaN  \n",
            "2                  10088639       NaN  \n",
            "3                  11195709       NaN  \n",
            "4                  11196080       NaN  \n",
            "...                     ...       ...  \n",
            "1318                    NaN  HDP01324  \n",
            "1498                    NaN  HDP01504  \n",
            "1499                    NaN  HDP01505  \n",
            "1500                    NaN  HDP01506  \n",
            "1501                    NaN  HDP01507  \n",
            "\n",
            "[1667 rows x 38 columns]\n",
            "==== Frequencies of several research networks in the combined dataset ========\n",
            "Research Network\n",
            "                       1203\n",
            "JCOIN                    73\n",
            "BACPAC                   57\n",
            "CTN                      44\n",
            "NCREW                    36\n",
            "ACT NOW                  34\n",
            "EPPIC-NET                33\n",
            "DATA 2 ACTION            30\n",
            "HBCD                     25\n",
            "HPC                      23\n",
            "PRISM                    23\n",
            "IMPOWR                   19\n",
            "HOPE                     15\n",
            "HEALING COMMUNITIES      11\n",
            "PAIN ERN                  8\n",
            "RE-JOIN                   7\n",
            "MEDTECH                   6\n",
            "PRECISION                 5\n",
            "A2CPS                     5\n",
            "MIRHIQL                   5\n",
            "MFMU                      3\n",
            "HARM REDUCTION            2\n",
            "Name: count, dtype: int64\n",
            "Fields and frequencies of any empty values in the final dataset\n",
            "{'Activity Code': 46,\n",
            " 'Administering IC': 46,\n",
            " 'Archived': 126,\n",
            " 'Award Year': 44,\n",
            " 'CEDAR Form %': 126,\n",
            " 'Checklist Exempt': 44,\n",
            " 'City': 51,\n",
            " 'Contact Email': 44,\n",
            " 'Contact PI': 46,\n",
            " 'Data Type': 1320,\n",
            " 'Do not Engage': 44,\n",
            " 'HEAL-Related': 240,\n",
            " 'Institution(s)': 46,\n",
            " 'NIH PO': 120,\n",
            " 'NIH PO Email': 1262,\n",
            " 'Platform Reg Time': 1130,\n",
            " 'Project End': 44,\n",
            " 'Project Start': 58,\n",
            " 'Repo per Platform': 1263,\n",
            " 'Reporter Link': 44,\n",
            " 'Research Focus': 253,\n",
            " 'Research Program': 370,\n",
            " 'SBIR/STTR': 46,\n",
            " 'State': 53,\n",
            " 'Title': 44,\n",
            " 'hdp_id': 1623,\n",
            " 'hdp_id_x': 170,\n",
            " 'hdp_id_y': 170,\n",
            " 'study_hdp_id': 126,\n",
            " 'study_hdp_id_appl': 170,\n",
            " 'study_most_recent_appl': 44}\n"
          ]
        }
      ],
      "source": [
        "logging.info(\"---- STEP 7: Combining everything together\")\n",
        "all_data = monday_board_update.combine_mysql_ctn(combined_data_ph1, ctn_fields_platform)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---- STEP 8: Final Manipulation of all the data to make it Monday Board ready\n",
            "Counts for study types in the final dataset\n",
            "study_type\n",
            "HDP           1497\n",
            "APPLIDONLY     126\n",
            "CTN             44\n",
            "Name: count, dtype: int64\n",
            "Setting empty cells to  '-' in the following colulmns:\n",
            "['Activity Code', 'Administering IC', 'Award Type', 'Contact Email', 'Contact PI', 'Data Type', 'Institution(s)', 'NIH PO', 'NIH PO Email', 'PI(s)', 'Project #', 'Repo per Platform', 'Reporter Link', 'Research Focus', 'Research Network', 'Research Program', 'Summary', 'Title', 'key', 'HDP appl_ID', 'Most Recent Appl_ID']\n"
          ]
        }
      ],
      "source": [
        "logging.info(\"---- STEP 8: Final Manipulation of all the data to make it Monday Board ready\")\n",
        "combined_data = monday_board_update.prepare_for_monday(all_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---- STEP 9: Final numbers and Export\n",
            "******************* MONDAY COMPARISON  ******************************************\n",
            "Number records from Monday already in final dataset: 0\n",
            "Number records from Monday that are not in final dataset (Consider these as discrepancies **Investigate**): 34\n",
            "Number records from final dataset that are not on Monday (Potentially new entries): 1667\n",
            "****** Investigate/Delete the following entries on Monday that are not in the final dataset\n",
            "[['HDP01518' '-' 'HDP']\n",
            " ['HDP01519' '-' 'HDP']\n",
            " ['HDP01514' '-' 'HDP']\n",
            " ['HDP01515' '-' 'HDP']\n",
            " ['HDP01517' '-' 'HDP']\n",
            " ['HDP01516' '-' 'HDP']\n",
            " ['HDP01513' '-' 'HDP']\n",
            " ['10428343_HDP00882' nan nan]\n",
            " ['10488140_HDP00883' nan nan]\n",
            " ['9673173_none' nan nan]\n",
            " ['9769689_none' nan nan]\n",
            " ['10934856' '10934856' 'APPLIDONLY']\n",
            " ['11129951' '11129951' 'APPLIDONLY']\n",
            " ['10881322' '10881322' 'APPLIDONLY']\n",
            " ['11009694' '11009694' 'APPLIDONLY']\n",
            " ['11044441' '11044441' 'APPLIDONLY']\n",
            " ['11046758' '11046758' 'APPLIDONLY']\n",
            " ['10936304' '10936304' 'APPLIDONLY']\n",
            " ['10936429' '10936429' 'APPLIDONLY']\n",
            " ['11167995' '11167995' 'APPLIDONLY']\n",
            " ['11134921' '11134921' 'APPLIDONLY']\n",
            " ['10935531' '10935531' 'APPLIDONLY']\n",
            " ['11141362' '11141362' 'APPLIDONLY']\n",
            " ['10818491' '10818491' 'APPLIDONLY']\n",
            " ['10684152' '10684152' 'APPLIDONLY']\n",
            " ['10663090' '10663090' 'APPLIDONLY']\n",
            " ['10885960' '10885960' 'APPLIDONLY']\n",
            " ['10744466' '10744466' 'APPLIDONLY']\n",
            " ['10920413' '10920413' 'APPLIDONLY']\n",
            " ['11055122' '11055122' 'APPLIDONLY']\n",
            " ['11302198' '11302198' 'APPLIDONLY']\n",
            " ['11055938' '11055938' 'APPLIDONLY']\n",
            " ['11062103' '11062103' 'APPLIDONLY']\n",
            " ['11059453' '11059453' 'APPLIDONLY']]\n",
            "******************* FINAL DATASET NUMBERS ******************************************\n",
            "Number records in the final dataset: 1667\n",
            "Making sure uniqueness of key values. Do we have one row per key(HDPID/APPLID)? ::::  True\n",
            "******************* EXPORTING ******************************************\n",
            "Exporting data to excel file at /Users/hinashah/Documents/HEAL/MondayUpdate_Feb2026/MondayBoard_Update.xlsx\n",
            "Exporting batch 1 (1500 records) to /Users/hinashah/Documents/HEAL/MondayUpdate_Feb2026/MondayBoard_Update_batch_1_records_1_to_1500.xlsx\n",
            "Exporting batch 2 (167 records) to /Users/hinashah/Documents/HEAL/MondayUpdate_Feb2026/MondayBoard_Update_batch_2_records_1501_to_1667.xlsx\n",
            "******************* DONE! ******************************************\n"
          ]
        }
      ],
      "source": [
        "logging.info(\"---- STEP 9: Final numbers and Export\")\n",
        "monday_board_update.export_finaldata(input_dir, combined_data, mondayboard_missingin_lookup, monday_board)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mondayboard_missingin_lookup[~(mondayboard_missingin_lookup.study_type == 'CTN')].Name.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "If the answer to: Making sure uniqueness of key values. Do we have one row per key(HDPID/APPLID)? is False, \n",
        "Run the script here.\n",
        "\"\"\"\n",
        "counts = combined_data.key.value_counts()\n",
        "counts[counts > 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "combined_data[combined_data.key == 'HDP01187']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def get_unique_values(df:pd.DataFrame, col_name:str='appl_id'):\n",
        "    if col_name in df.columns:\n",
        "        return df[ ~pd.isna(df[col_name])][col_name].drop_duplicates()\n",
        "    return None\n",
        "\n",
        "convert_dict = {'appl_id':str}\n",
        "resnet_df = pd.read_csv(input_dir/\"research_networks.csv\", low_memory=False, dtype=convert_dict)\n",
        "logging.info(f\"Research Network table has: {len(resnet_df)} entries, with {len(get_unique_values(resnet_df))} appl_ids\")\n",
        "\n",
        "appl_ids = gt_file[['appl_id', 'study_most_recent_appl']].drop_duplicates()\n",
        "resnets = resnet_df[~pd.isna(resnet_df.res_net)][['appl_id', 'res_net']]\n",
        "\n",
        "resnets_merged = pd.merge(appl_ids, resnets, how='left', left_on='study_most_recent_appl', right_on='appl_id')\n",
        "resnets_merged_again = pd.merge(resnets_merged, resnets, how='left', left_on='appl_id_x', right_on='appl_id')\n",
        "\n",
        "resnets_merged_again.drop_duplicates(inplace=True)\n",
        "resnets_merged_again.to_csv(\"/tmp/resnet.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resnet_added = pd.merge(appl_ids, resnet_df[['appl_id', 'res_net']], how = 'left', left_on='appl_id', right_on='appl_id' )\n",
        "resnet_most_recent_appl_id = resnet_added[~pd.isna(resnet_added.res_net)][['study_most_recent_appl', 'res_net']]\n",
        "resnet_added_updated = pd.merge(appl_ids, resnet_most_recent_appl_id, how='left', left_on='study_most_recent_appl', right_on='study_most_recent_appl')\n",
        "resnet_df_new = resnet_added_updated[['study_most_recent_appl', 'res_net']].drop_duplicates()\n",
        "resnet_added_updated.to_csv(\"/tmp/tmp_resnet_udpated.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting new HTTPS connection (1): healdata.org:443\n",
            "https://healdata.org:443 \"GET /mds/metadata?_guid_type=discovery_metadata&limit=2000 HTTP/11\" 200 None\n",
            "Starting new HTTPS connection (1): healdata.org:443\n",
            "https://healdata.org:443 \"GET /mds/metadata?_guid_type=unregistered_discovery_metadata&limit=2000 HTTP/11\" 200 None\n",
            "1149\n"
          ]
        }
      ],
      "source": [
        "### BLOCK to compare Platform MDS list of studies vs. Monday Board studies.\n",
        "\n",
        "\n",
        "import requests\n",
        "mds_metadata_endpoint = 'https://healdata.org/mds/metadata'\n",
        "HEAL_STUDY_GUID_TYPES = [\n",
        "    'discovery_metadata',                   # Fully registered studies.\n",
        "    'unregistered_discovery_metadata'       # Studies added to the Platform MDS but without the investigator registering the study.\n",
        "]\n",
        "\n",
        "metadata_ids = []\n",
        "for heal_study_guid_type in HEAL_STUDY_GUID_TYPES:\n",
        "    result = requests.get(mds_metadata_endpoint, params={\n",
        "            '_guid_type': heal_study_guid_type,\n",
        "            'limit': 2000,\n",
        "        })\n",
        "    if not result.ok:\n",
        "            print(f'Could not retrieve metadata list for guid_type {heal_study_guid_type}: {result}')\n",
        "    metadata_ids.extend(result.json())\n",
        "\n",
        "print(len(metadata_ids))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1128\n"
          ]
        }
      ],
      "source": [
        "hdps_platform = combined_data[(combined_data.study_type.isin(['HDP', 'CTN'])) & (combined_data['Archived'] != 'archived')]\n",
        "print(len(hdps_platform))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "21\n",
            "HDP00881\n",
            "HDP00882\n",
            "HDP00883\n",
            "HDP00884\n",
            "HDP00885\n",
            "HDP00886\n",
            "HDP01513\n",
            "HDP01514\n",
            "HDP01515\n",
            "HDP01516\n",
            "HDP01517\n",
            "HDP01518\n",
            "HDP01519\n",
            "HDP01678\n",
            "HDP01679\n",
            "HDP01680\n",
            "HDP01681\n",
            "HDP01682\n",
            "HDP01683\n",
            "HDP01684\n",
            "HDP01685\n"
          ]
        }
      ],
      "source": [
        "missing_hdps = [k for k in metadata_ids if k not in hdps_platform.key.values]\n",
        "missing_hdps.sort()\n",
        "print(len(missing_hdps))\n",
        "for k in missing_hdps:\n",
        "    print(k)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
