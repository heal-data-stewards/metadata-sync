{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook will develp the SOP for updating the Monday.com studies board consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = Path(\"/Users/hinashah/Documents/HEAL/TablesForSarah\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_values(df:pd.DataFrame, col_name:str='appl_id'):\n",
    "    if col_name in df.columns:\n",
    "        return df[ ~pd.isna(df[col_name])][col_name].drop_duplicates()\n",
    "    return None\n",
    "\n",
    "def get_na_count(df:pd.DataFrame, col_name:str='appl_id'):\n",
    "    if col_name in df.columns:\n",
    "        return len(df[pd.isna(df[col_name])])\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_to_gather = [ 'hdp_id',\n",
    "                'ctc_pi_nm',\n",
    "                'proj_num',\n",
    "                'proj_title',\t\n",
    "                'rfa',\n",
    "                'res_net',\t\n",
    "                'res_prg',\n",
    "                'proj_abs',\n",
    "                'adm_ic',\n",
    "                'proj_num_spl_ty_code',\n",
    "                'proj_num',\n",
    "                'fisc_yr',\n",
    "                'org_nm',\n",
    "                'prg_ofc',\n",
    "                'proj_end_date',\n",
    "                'proj_num',\n",
    "                'proj_num_spl_act_code',\n",
    "                'tot_fund',\n",
    "                'proj_ser_num',\n",
    "                'pi_email',\t\n",
    "                'clinical_trials_study_ID',\n",
    "                'repository_name'\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Awards table has: 1618 entries, with 1618 appl_ids\n",
      "Reporter table has: 1617 entries, with 1617 appl_ids\n",
      "Platform generated table has: 1320 entries, with 1311 appl_ids\n",
      "Platform table has 1311 unique HDP IDs\n",
      "Repo mapping table has: 1323 entrie, with 1323 appl_ids\n",
      "Repo mapping table has: 1059 entrie, with 1059 appl_ids\n",
      "Research Network table has: 1669 entrie, with 1669 appl_ids\n"
     ]
    }
   ],
   "source": [
    "# Get rest of the tables\n",
    "convert_dict = {'appl_id':str}\n",
    "awards_df = pd.read_csv(input_dir/\"awards.csv\", low_memory=False, dtype=convert_dict)\n",
    "awards_df = awards_df.dropna(how='all')\n",
    "print(f\"Awards table has: {len(awards_df)} entries, with {len(get_unique_values(awards_df))} appl_ids\")\n",
    "reporter_df = pd.read_csv(input_dir/\"reporter.csv\", low_memory=False, dtype=convert_dict)\n",
    "reporter_df = reporter_df.dropna(how='all')\n",
    "print(f\"Reporter table has: {len(reporter_df)} entries, with {len(get_unique_values(reporter_df))} appl_ids\")\n",
    "progress_tracker_df = pd.read_csv(input_dir/\"progress_tracker.csv\", low_memory=False, dtype=convert_dict)\n",
    "print(f\"Platform generated table has: {len(progress_tracker_df)} entries, with {len(get_unique_values(progress_tracker_df))} appl_ids\")\n",
    "print(f\"Platform table has {len(get_unique_values(progress_tracker_df))} unique HDP IDs\")\n",
    "repo_maping_df = pd.read_csv(input_dir/\"repo_mapping.csv\", low_memory=False, dtype=convert_dict)\n",
    "print(f\"Repo mapping table has: {len(repo_maping_df)} entrie, with {len(get_unique_values(repo_maping_df))} appl_ids\")\n",
    "pi_emails_df = pd.read_csv(input_dir/\"pi_emails.csv\", low_memory=False, dtype=convert_dict)\n",
    "print(f\"Repo mapping table has: {len(pi_emails_df)} entrie, with {len(get_unique_values(pi_emails_df))} appl_ids\")\n",
    "resnet_df = pd.read_csv(input_dir/\"research_networks.csv\", low_memory=False, dtype=convert_dict)\n",
    "print(f\"Research Network table has: {len(resnet_df)} entrie, with {len(get_unique_values(resnet_df))} appl_ids\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_data(df1:pd.DataFrame, df2:pd.DataFrame, term_list:list, on_term='appl_id'):\n",
    "    # Make sure that on_term is in first dataframe\n",
    "    if on_term not in df1.columns:\n",
    "        print(f\"Could not find on_term {on_term} in first dataframe, quitting\")\n",
    "        return None\n",
    "\n",
    "    df2_include_columns = [on_term] + [k for k in df2.columns if k in term_list and k not in df1.columns]\n",
    "    new_df = pd.merge(df1, df2[ df2_include_columns], on=on_term, how='outer')\n",
    "\n",
    "    if on_term+\"_1\" in new_df.columns and on_term+\"_2\" in new_df.columns:\n",
    "        print(f\"Need to merge on term columns\")\n",
    "        new_df[on_term] = [ t2 if pd.isna(t1) else t1 for (t1, t2) in new_df[[on_term+\"_1\", on_term+\"_2\"]] ]\n",
    "        new_term.delete(columns=[on_term+\"_1\", on_term+\"_2\"], inplace=True)\n",
    "    return new_df\n",
    "\n",
    "def check_termlist(df:pd.DataFrame, term_list:list):\n",
    "    missing_terms = [k for k in term_list if k not in df.columns]\n",
    "    print(f\"Input Data Frame is missing {len(missing_terms)} terms: \\n **** {missing_terms}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['appl_id', 'rfa', 'res_prg']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['appl_id'] + [k for k in awards_df.columns if k in fields_to_gather]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1618\n",
      "1618\n",
      "1668\n",
      "1670\n",
      "1684\n",
      "1735\n",
      "Input Data Frame is missing 3 terms: \n",
      " **** ['proj_yr_end', 'proj_yr_end', 'spl_act_code']\n"
     ]
    }
   ],
   "source": [
    "start_df = awards_df[ ['appl_id'] + [k for k in awards_df.columns if k in fields_to_gather] ].drop_duplicates()\n",
    "print(len(start_df))\n",
    "df_next = combine_data(start_df, reporter_df, fields_to_gather)\n",
    "print(len(df_next))\n",
    "df_next = combine_data(df_next, progress_tracker_df, fields_to_gather)\n",
    "print(len(df_next))\n",
    "df_next = combine_data(df_next, repo_maping_df, fields_to_gather)\n",
    "print(len(df_next))\n",
    "df_next = combine_data(df_next, pi_emails_df, fields_to_gather)\n",
    "print(len(df_next))\n",
    "df_next = combine_data(df_next, resnet_df, fields_to_gather)\n",
    "print(len(df_next))\n",
    "\n",
    "check_termlist(df_next, fields_to_gather)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_next.to_csv(input_dir/\"MySqlExportForSarah.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
